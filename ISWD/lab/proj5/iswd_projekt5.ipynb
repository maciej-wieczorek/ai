{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Projekt Preference learning\n",
        "### Maciej Wieczorek, 148141\n",
        "### Kacper Perz, 145261"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DCgO1quZT14"
      },
      "source": [
        "## 1. Zbiór danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FpcMOwrKSnNF",
        "outputId": "983505eb-03ba-4d8f-9d79-1603fff228fb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('cpu.csv', header=None, names=['f1','f2','f3','f4','f5','f6','class'])\n",
        "dataset.loc[dataset['class'] < 2, 'class'] = int(0)\n",
        "dataset.loc[dataset['class'] >= 2, 'class'] = int(1)\n",
        "X = dataset.loc[:, dataset.columns != 'class']\n",
        "y = dataset['class']\n",
        "dataset.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMOAuQmSZT17"
      },
      "source": [
        "## 2. Prosty, interpretowalny model ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOc03TT35yXl",
        "outputId": "22439910-347c-4e54-a783-80035c4e4b2d"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
        "\n",
        "# Initialize the model\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',  # for multi-class classification\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train.values, y_train)\n",
        "\n",
        "# Make predictions\n",
        "pred_probs = model.predict_proba(X_test.values)  # This returns a probability distribution over classes\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Binarize the true labels for AUC calculation\n",
        "y_test_bin = label_binarize(y_test, classes=[0, 1])\n",
        "\n",
        "roc = roc_auc_score(preds, y_test)\n",
        "print(f\"AUC: {roc:.2f}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, preds, average='weighted')\n",
        "print(f\"F1-score: {f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcdWzAW_6J7r",
        "outputId": "0462edf0-6c01-45e8-ee6e-bfe677898d4f"
      },
      "outputs": [],
      "source": [
        "dump_list = model.get_booster().get_dump()\n",
        "num_trees = len(dump_list)\n",
        "print(num_trees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "lhd5L2yR4CTm",
        "outputId": "fbd606dc-57f5-4e35-bde8-7b889cfc6f68"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xgb.plot_tree(model, num_trees=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W13OQ8vF5I0w"
      },
      "outputs": [],
      "source": [
        "feature_important = model.get_booster().get_score(importance_type='weight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBp_Zw8ZDwLY",
        "outputId": "dda18570-c0eb-43ce-a0e5-3ed2b238841a"
      },
      "outputs": [],
      "source": [
        "feature_important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "6JMDCF5rEOho",
        "outputId": "198ef5e6-8091-47ae-85d3-fae67188e049"
      },
      "outputs": [],
      "source": [
        "xgb.plot_importance(model, max_num_features = 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fWoyfVPZT18"
      },
      "source": [
        "#### 2.1 Wyjaśnienie decyzji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrj3Ug9nTvOh",
        "outputId": "ae6f5425-66d8-47ed-d215-55c5a859fadb"
      },
      "outputs": [],
      "source": [
        "!pip install shap\n",
        "\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpk8QN6tMtqR",
        "outputId": "cbdc88e3-663c-4d10-c431-3a835a6f6ca8"
      },
      "outputs": [],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYGmTq2bnW4N"
      },
      "source": [
        "# Zadanie 2.1.1 i 2.1.2\n",
        "\n",
        "Dla xgboosta wzięliśmy 3 pierwsze przykłady ze zbioru testowego. Za pomocą\n",
        "shap'a sprawdziliśmy, które cechy miały wpływ na predykcję danej klasy. Przedstawiają to poniższe wykresy.\n",
        "\n",
        "Dla x_0 (klasa '0') największą siłę miała cecha f3, dla x_1 (klasa '1') cecha f4 i dla x_2 (klasa '0') cecha f3. We wszystkich przykładach zdecydowaliśmy się zmienić nieznacznie cechę f3 widząc (na wykresach na samym dole sekcji), że ma największy wpływ na największą liczbę przykładów i stanowi uniwersalny wyznacznik.\n",
        "\n",
        "# Zadanie 2.1.3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "gj0la-lfPjlt",
        "outputId": "ce93110e-0ae3-45ae-fef6-017c7c260eb6"
      },
      "outputs": [],
      "source": [
        "# creating an explainer for our model\n",
        "explainer = shap.TreeExplainer(model)\n",
        "\n",
        "# finding out the shap values using the explainer\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "print(shap_values.shape)\n",
        "\n",
        "# Expected/Base/Reference value = the value that would be predicted if we didn’t know any features of the current output”\n",
        "print('Expected Value:', explainer.expected_value)\n",
        "\n",
        "# displaying the first 5 rows of the shap values table\n",
        "pd.DataFrame(shap_values).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuKKr4eDYXAA",
        "outputId": "d75f91b8-5054-4c61-a1b2-e84c50f9ad8b"
      },
      "outputs": [],
      "source": [
        "x_0, y_0 = X_test.iloc[0,:], y_test.values[0]\n",
        "x_1, y_1 = X_test.iloc[1,:], y_test.values[1]\n",
        "x_2, y_2 = X_test.iloc[2,:], y_test.values[2]\n",
        "\n",
        "print(x_0, y_0)\n",
        "print(x_1, y_1)\n",
        "print(x_2, y_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "kDShM2awZopG",
        "outputId": "bfe765d4-a309-42bd-9cb2-986df2caad97"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value,\n",
        "                shap_values[0,:], x_0) # ma label = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "zzxyO-QAaQx0",
        "outputId": "84d8f279-caef-4f67-e4ec-e34672732254"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value,\n",
        "                shap_values[1,:], x_1) # ma label = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "NaSa3lqRacxJ",
        "outputId": "a6d93b86-913f-4495-a066-1de9b8a09ef6"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value,\n",
        "                shap_values[2,:], x_2) # ma label = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lCmZJb-apu-",
        "outputId": "f2830513-5d3e-4bdb-9e1c-cdc2e2b10871"
      },
      "outputs": [],
      "source": [
        "# f4 u przykladow o klasie = 0 wynosi czesto 0. shap podpowiada, ze to wlasnie ta cecha\n",
        "# i ta wartosc cechy popycha przykladow od klasy 0\n",
        "# zwiekszmy te ceche i zrobmy predykcje\n",
        "\n",
        "x_0['f3'] = 1.2\n",
        "print(x_0.values.reshape(1, 6).shape)\n",
        "\n",
        "print(model.predict(x_0.values.reshape(1,6)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvO_7C40et1d",
        "outputId": "92ab25a3-a1b8-41ea-e3ae-11de3a7bacb7"
      },
      "outputs": [],
      "source": [
        "# przyklad x_1 nalezy do klasy '1'. zmienmy 'f4' na 0\n",
        "\n",
        "x_1['f3'] = 0.08\n",
        "print(x_1.values.reshape(1, 6).shape)\n",
        "\n",
        "print(model.predict(x_1.values.reshape(1,6)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8J64bXNgp-v",
        "outputId": "efb59337-a13d-469f-b843-eb1bcafb3b4f"
      },
      "outputs": [],
      "source": [
        "# przyklad x_2 nalezy do klasy '0'. zmienmy 'f4' na 0.1\n",
        "\n",
        "x_2['f3'] = 0.12\n",
        "print(x_2.values.reshape(1, 6).shape)\n",
        "\n",
        "print(model.predict(x_2.values.reshape(1,6)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DSO5E-LrgdPS",
        "outputId": "8ecb0186-ebc0-4b79-9d21-5351f3859455"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.summary_plot(shap_values,\n",
        "                  X_test, plot_type=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ONKcL7o8PkAV",
        "outputId": "a0f6d1a5-be33-45bd-f3fe-c4279bca72eb"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "# wniosek: f3 ma wpływ na wszystkie przykłady i z największą siłą, jako że jest na szczycie\n",
        "# i jako że wartości SHAP są dla tej cechy największe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGwiqo_frH69"
      },
      "source": [
        "## Próbkowanie przestrzeni\n",
        "Hipoteza: wieksza wartosc f3 powinna spowodowac wiecej predykcji klasy '1'\n",
        "\n",
        "Po zmianie f3: hipoteza potwierdzona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y6L-LE-rNgF",
        "outputId": "3336aad7-d52a-4b2a-cd2e-45d691c3f2da"
      },
      "outputs": [],
      "source": [
        "# hipoteza: wieksza wartosc f3 powinna spowodowac wiecej predykcji klasy '1'\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X_hip_test = X_test.copy()\n",
        "X_hip_pred = model.predict(X_hip_test)\n",
        "print('Licznosc klasy 0:', np.sum(y_test == 0))\n",
        "print('Licznosc klasy 1:', np.sum(y_test == 1))\n",
        "print('Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "print('Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "X_hip_test['f3'] += 0.04\n",
        "X_hip_pred = model.predict(X_hip_test)\n",
        "print('Po zmianie f3. Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "print('Po zmianie f3. Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "# --------\n",
        "# X_hip_test = X_test.copy()\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Licznosc klasy 0:', np.sum(y_test == 0))\n",
        "# print('Licznosc klasy 1:', np.sum(y_test == 1))\n",
        "# print('Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "# X_hip_test['f1'] -= 1\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Po zmianie f1. Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Po zmianie f1. Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "\n",
        "# --------\n",
        "# X_hip_test = X_test.copy()\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Licznosc klasy 0:', np.sum(y_test == 0))\n",
        "# print('Licznosc klasy 1:', np.sum(y_test == 1))\n",
        "# print('Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "# X_hip_test['f2'] += 1\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Po zmianie f2. Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Po zmianie f2. Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "# --------\n",
        "# X_hip_test = X_test.copy()\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Licznosc klasy 0:', np.sum(y_test == 0))\n",
        "# print('Licznosc klasy 1:', np.sum(y_test == 1))\n",
        "# print('Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "# X_hip_test['f4'] += 0.1\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Po zmianie f4. Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Po zmianie f4. Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# X_hip_test = X_test.copy()\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Licznosc klasy 0:', np.sum(y_test == 0))\n",
        "# print('Licznosc klasy 1:', np.sum(y_test == 1))\n",
        "# print('Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "# X_hip_test['f6'] -= 20\n",
        "# X_hip_pred = model.predict(X_hip_test)\n",
        "# print('Po zmianie f5. Licznosc predykcji klasy 0:', np.sum(X_hip_pred == 0))\n",
        "# print('Po zmianie f5. Licznosc predykcji klasy 1:', np.sum(X_hip_pred == 1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# rosnace - f2, f4 (powyzej 0.1 rzeczy juz sa nierozroznialne i zawsze wedruja do klasy 1)\n",
        "# malejace - f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt2wNzCuZT19"
      },
      "source": [
        "#### 2.2 Interpretacja modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij8AQLZh3TUM"
      },
      "source": [
        "Czy na podstawie uzyskanych parametrów możemy powiedzieć coś o preferencjach użytkowników?\n",
        "\n",
        "Zazwyczaj tak. Jeżeli dana cecha ma znaczący wpływ na przydział do danej klasy, to znaczy własnie, że jakaś cecha odgrywa większą rolę w klasyfikacji danego przykładu. Np. wysoka wartość na f3 może mieć decydujący wpływ na przydział do klasy '1' i przyrost jednostki w na tej cesze będzie preferowany nad proporcjonalny przyrost na innej cesze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "S0LUiOwt0XZD",
        "outputId": "76b4575a-98d2-46cf-f4d7-f6db71b40b2a"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGz8hRYs37Qv"
      },
      "source": [
        "Jaki jest wpływ każdego z kryteriów? Czy są jakieś kryteria, które nie mają żadnego znaczenia, czy też mają wpływ decydujący.\n",
        "\n",
        "Oprócz powyższego wykresu (ważność cech według xgboosta) szerszej odpowiedzi udziela także wykres poniższy, generowany przez shap'a. Z ilustracji można wyciągnąć następujące wnioski:\n",
        "- Cechy są sortowane według sumy wartości SHAP we wszystkich próbkach.\n",
        "- Warto zauważyć, że f3 ma większy wpływ na model niż f4. (Ponieważ znajdują się one na górze, a pasek Feature Value dla obu cech wskazuje tam po mniej więcej po równo)\n",
        "- Dla najmniejszej liczby przykładów znaczenie mają cechy f5 i f6, chociaż jeżeli już dla jakichś mają, to mają ten wpływ całkiem spory (czerwony kolor na feature value), w przeciwieństwie do f1, które może być istotne dla odrobinę większej liczby przykładów, ale bez większej wartości (brak czerwonego).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sYuV8npB36ng",
        "outputId": "668a0e2d-fa2a-42d6-b14e-2edd3dfdec3e"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.summary_plot(shap_values, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQBELbek6Diq"
      },
      "source": [
        "Jaki jest charakter danego kryterium: zysk, koszt, niemonotoniczne?\n",
        "\n",
        "\n",
        "Kryterium f2 i f4 jest typu zysk, przy czym powyżej pewnej wartości zwracana klasa zawsze wynosi '1'.\n",
        "Kryterium f1 jest typu koszt.\n",
        "\n",
        "Do wyciągnięcia tych wniosków zwiększaliśmy i zmniejszaliśmy wartości kolejnych cech przykładów testowych, a następnie tak zmienione przykłady przepuszczaliśmy przez wcześniej wytrenowany model i patrzyliśmy czy i w jakich proporcjach zmieniły się predykcje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlIvNa19AqFK"
      },
      "source": [
        "Czy istnieją jakieś progi preferencji? Czy istnieją oceny kryteriów, które są nierozróżnialne z punktu widzenia preferencji?\n",
        "\n",
        "Dobrym przykładem jest f4. Cecha f4 dla przykładów o klasie '0' ma wartość=0. Jeżeli zwiększymy tę wartość"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytmn89YaAmt9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlvW2BKVZT19"
      },
      "source": [
        "## 3. interpretowalny model ANN-MCDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ynvi49t8ZT19"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "\n",
        "dataset = pd.read_csv('cpu.csv', header=None, names=['f1','f2','f3','f4','f5','f6','class'])\n",
        "dataset.loc[dataset['class'] < 2, 'class'] = 0\n",
        "dataset.loc[dataset['class'] >= 2, 'class'] = 1\n",
        "X = dataset.loc[:, dataset.columns != 'class'].to_numpy()\n",
        "y = dataset['class'].to_numpy()\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class ANNChConstr(tf.keras.Model):\n",
        "    def __init__(self, num_features):\n",
        "        super(ANNChConstr, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        \n",
        "        # wagi kryteriów\n",
        "        self.wj = tf.Variable(tf.ones([num_features]), constraint=tf.keras.constraints.NonNeg())\n",
        "        # wagi interakcji\n",
        "        self.wjl = tf.Variable(tf.zeros([num_features, num_features]))\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # Obliczanie sumy ważonej dla każdego kryterium\n",
        "        weighted_sum = tf.linalg.matvec(inputs, self.wj)\n",
        "        \n",
        "        # Obliczanie interakcji między kryteriami\n",
        "        interactions = 0\n",
        "        for i in range(self.num_features):\n",
        "            for j in range(i + 1, self.num_features):\n",
        "                interactions += self.wjl[i, j] * tf.math.minimum(inputs[:, i], inputs[:, j])\n",
        "        \n",
        "        # Łączenie wyników z obu warstw\n",
        "        output = weighted_sum + interactions\n",
        "        \n",
        "        # Normalizacja\n",
        "        normalization_factor = tf.reduce_sum(self.wj) + tf.reduce_sum(self.wjl)\n",
        "        normalized_output = output / normalization_factor\n",
        "        \n",
        "        return normalized_output\n",
        "\n",
        "def mobius_transform(X):\n",
        "    # ???\n",
        "    return X\n",
        "\n",
        "def avg_regret_loss(y_true, y_pred):\n",
        "    regret = tf.maximum(y_true - y_pred, y_pred - y_true, 0)\n",
        "    return tf.reduce_mean(regret)\n",
        "\n",
        "mobius_transform(X_train)\n",
        "model = ANNChConstr(X_train.shape[1])\n",
        "model.compile(optimizer='adam', loss=avg_regret_loss)\n",
        "model.fit(X_train, y_train, epochs=1000, batch_size=X_train.shape[0], verbose=0)\n",
        "model.evaluate(X_test, y_test, batch_size=X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_prediction_classes(y_pred):\n",
        "    return (y_pred > 0.5).astype(np.uint8)\n",
        "\n",
        "y_pred = get_prediction_classes(model.predict(X_test))\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wj = model.get_weights()[0]\n",
        "wjl = model.get_weights()[1]\n",
        "print('Wagi kryteriów')\n",
        "print(np.round(wj, 4))\n",
        "print('Wagi interakcji (tylko górna przekątna)')\n",
        "print(np.round(wjl, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-GKhctZT1-"
      },
      "source": [
        "#### 3.1 Wyjaśnienie decyzji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Predykcje\")\n",
        "print(get_prediction_classes(model.predict(X_test[:3], verbose=0)))\n",
        "print(\"Warianty\")\n",
        "print(X_test[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Na przydział do klasy głównie wpływają kryteria: f3, f4 co można wywnioskować po ich wagach.\n",
        "Wariant pierwszy oraz trzeci została zaklasyfikowana jako 0, ponieważ mają niskie wartości na kryteriach f3 i f4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(model, X_test[:3])\n",
        "shap_values = explainer(X_test[:3])\n",
        "shap.plots.waterfall(shap_values[0])\n",
        "shap.plots.waterfall(shap_values[1])\n",
        "shap.plots.waterfall(shap_values[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dla wariantu pierwszego istotne są kryteria f4, f5, i f1\n",
        "Dla wariantu drugiego i trzeciego istotne są kryteria f4 oraz f3, które również mają wysoką wagę interakcji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5YenAafZT1-"
      },
      "source": [
        "#### 3.2 Interpretacja modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shapley_index():\n",
        "    wj = model.get_weights()[0]\n",
        "    wjl = model.get_weights()[1]\n",
        "    wjl_sums = {}\n",
        "    for i in range(len(wj)):\n",
        "        for j in range(i+1, len(wj)):\n",
        "            w = wjl[i][j]\n",
        "            if i not in wjl_sums:\n",
        "                wjl_sums[i] = 0\n",
        "            if j not in wjl_sums:\n",
        "                wjl_sums[j] = 0\n",
        "            wjl_sums[i] += w / 2\n",
        "            wjl_sums[j] += w / 2\n",
        "        wjl_sums[i] += w\n",
        "\n",
        "    return wjl_sums\n",
        "shapley_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtDz-2B9ZT1-"
      },
      "source": [
        "## 4. Złożony model sici neuronowej zawierającej kilka warstw ukrytych i nieliniową funkcję aktywacji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 5), activation='relu', max_iter=500, random_state=1)\n",
        "mlp.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = mlp.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}, F1: {f1}, AUC: {auc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, layer in enumerate(mlp.coefs_):\n",
        "    print(f'layer {i}: {np.round(layer, 4)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IDdT84nZT1-"
      },
      "source": [
        "#### 4.1 Wyjaśnienie decyzji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# explainer = shap.KernelExplainer(mlp.predict_proba, X_train, link=\"logit\")\n",
        "# shap_values = explainer.shap_values(X_test, nsamples=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsI1ASREZT1_"
      },
      "source": [
        "#### 4.2 Interpretacja modelu"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
