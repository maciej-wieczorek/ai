{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_r0j8Xuqsga"
      },
      "source": [
        "# Widzenie komputerowe - Laboratoria nr 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVWBS5p-r5j9"
      },
      "source": [
        "## Opis laboratoriów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2FzMMMr9kr"
      },
      "source": [
        "Segmentacja obrazu bazująca na:\n",
        "- progowaniu\n",
        "- analizie skupień,\n",
        "- wykrywaniu cech obrazu (np. krawędzi),\n",
        "- podziale i rozroście,\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJXpBTXtET5"
      },
      "source": [
        "## Funkcje pomocnicze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfiyoH2V2Htn"
      },
      "source": [
        "### Niezbędne biblioteki\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR2UJpj5IoR_"
      },
      "source": [
        "- OpenCV - główna biblioteka do przetwarzania obrazów, zawierająca operacje i algorytmy na obrazach,\n",
        "- matplotlib, pillow, pandas (głównie do wizualizacji),\n",
        "- numpy - przechowywanie i operacje na danych,\n",
        "- dodatkowo: json, os, skimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouwg_O1ksz98",
        "outputId": "f5bbf034-2150-45ac-e73f-1c7a2bd5bccf"
      },
      "outputs": [],
      "source": [
        "# to have popular descriptors like SIFT\n",
        "!pip install -U opencv-python\n",
        "!pip install -U opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE5KwNqA3Ots"
      },
      "outputs": [],
      "source": [
        "# import niezbędnych bibliotek\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "import PIL\n",
        "from pandas import DataFrame\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "from skimage.exposure import rescale_intensity\n",
        "import json\n",
        "import os\n",
        "from itertools import product\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import plotly.graph_objects as go\n",
        "import sys\n",
        "\n",
        "pd.options.display.html.border = 0\n",
        "pd.options.display.float_format = '{:,.2f}'.format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmmZh-IZ3o43"
      },
      "source": [
        "### Zbiory danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du-h1aTru9ES"
      },
      "source": [
        "* obraz Lenna (dostępny pod [linkiem](http://www.lenna.org/)) - jeden z najbardziej popularnych obrazów wykorzystywanych historycznie do kompresji i przetwarzania obrazów,\n",
        "* clevr - obraz prezentacyjny pochodzący ze zbioru danych CLEVR zajmującego się problemem Visual Query Answering,\n",
        "* graf - przykładowy obraz grafiti z repozytorium OpenCV,\n",
        "* sudoku - przykładowy obraz sudoku z repozytorium OpenCV,\n",
        "* skittles - obraz skittlesów pochodzący z wikimedia.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV4aWjegtCKx"
      },
      "outputs": [],
      "source": [
        "# pobranie niezbędnych bibliotek\n",
        "!wget -O lena_std.tif http://www.lenna.org/lena_std.tif\n",
        "!wget -O clevr.jpg https://cs.stanford.edu/people/jcjohns/clevr/teaser.jpg\n",
        "!wget -O graf.png https://github.com/opencv/opencv/raw/master/samples/data/graf1.png\n",
        "!wget -O sudoku.png https://raw.githubusercontent.com/opencv/opencv/master/samples/data/sudoku.png\n",
        "!wget -O skittles.jpg https://upload.wikimedia.org/wikipedia/commons/c/ca/Skittles-Louisiana-2003.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3desh1dBMaw"
      },
      "source": [
        "### Wizualizacja\n",
        "\n",
        "- imshow() - wizualizacja obrazów BGR/BGRA,\n",
        "- h() - wizualizacja tabeli w postaci numerycznej,\n",
        "- h_color() - wizualizacja tabeli w postaci kolorystycznej,\n",
        "- h_grid() - wizualizacja rastra ARC,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCHL_RVqunsJ"
      },
      "outputs": [],
      "source": [
        "def imshow(a):\n",
        "  a = a.clip(0, 255).astype('uint8')\n",
        "  if a.ndim == 3:\n",
        "    if a.shape[2] == 4:\n",
        "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "    else:\n",
        "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "  display(PIL.Image.fromarray(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWCxEvekEKex"
      },
      "outputs": [],
      "source": [
        "css = \"\"\"\n",
        "<style type=\"text/css\">\n",
        "  table, td, table.dataframe, table.dataframe td {\n",
        "    border: 1px solid black;    //border: double;\n",
        "    border-collapse: collapse;\n",
        "    border-style: solid;\n",
        "    border-spacing: 0px;\n",
        "    background-color: rgb(250,250,250);\n",
        "    width: 18px;\n",
        "    height: 18px;\n",
        "    text-align: center;\n",
        "    transform: scale(1.0);\n",
        "    margin: 2px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "def h(s):\n",
        "  return display(HTML(css + DataFrame(s).to_html(header=False, index=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK2Em3Y6fQBS"
      },
      "outputs": [],
      "source": [
        "def h_color(a, cmap='gray', scale=2):\n",
        "  s = [a.shape[0] * scale, a.shape[1] * scale]\n",
        "  plt.figure(figsize=s)\n",
        "  plt.tick_params(\n",
        "    axis='both', which='both',\n",
        "    bottom=False, top=False,\n",
        "    labelbottom=False, labelleft=False, left=False, right=False\n",
        "  )\n",
        "  plt.imshow(a, cmap=cmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VabMXJfTc5wq"
      },
      "outputs": [],
      "source": [
        "cmap = ListedColormap([\n",
        "    'black', 'tomato', 'chocolate', 'darkorange',\n",
        "    'gold', 'olive', 'green', 'deepskyblue',\n",
        "    'blueviolet', 'hotpink'\n",
        "])\n",
        "\n",
        "def h_grid(grid, scale=1):\n",
        "  h_color(grid, cmap, scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZngoUIAXR_f"
      },
      "outputs": [],
      "source": [
        "def pix_show(pixels, skip_each=1, height=800, width=800, colors=None):\n",
        "  pixels = pixels[::skip_each]\n",
        "  if colors is None: colors = pixels[:, ::-1]\n",
        "  else: colors = colors[::skip_each]\n",
        "  b, g, r = pixels[:, 0], pixels[:, 1], pixels[:, 2]\n",
        "  fig = go.Figure(data=[\n",
        "    go.Scatter3d(x=b, y=g, z=r, mode='markers', marker={\n",
        "        'size': 2,\n",
        "        'color': colors,\n",
        "        'opacity': 0.7\n",
        "    })\n",
        "  ], layout_xaxis_range=[0, 1], layout_yaxis_range=[0, 1])\n",
        "  scene = {\n",
        "      'xaxis': dict(title='Blue'),\n",
        "      'yaxis': dict(title='Green'),\n",
        "      'zaxis': dict(title='Red')\n",
        "  }\n",
        "  fig.update_layout(autosize=False, height=height, width=width, scene=scene, showlegend=True)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSxfx6UE0lx6"
      },
      "source": [
        "# Segmentacja obrazu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq17Ur3n0ocX"
      },
      "source": [
        "## Segmentacja poprzez progowanie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoLXtzXSti4B"
      },
      "source": [
        "Najprostszym sposobem aby posegmentować obraz jest wykonanie progowania na intensywnościach pikseli. Operacja progowania polega na zastąpieniu pewną stałą wartością wszystkich intensywności powyżej pewnego progu, oraz inną wartością poniżej tego progu.\n",
        "\n",
        "Istnieje również segmentacja z wieloma progami, co zostało zaprezentowane już na pierwszych zajęciach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "0w_W_bNauD5v",
        "outputId": "d2daed53-9104-4617-b457-93a39fc18872"
      },
      "outputs": [],
      "source": [
        "lena = cv2.imread('./lena_std.tif', cv2.IMREAD_COLOR)\n",
        "imshow(lena)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "N2XJTzfXuFBv",
        "outputId": "99ad2a1a-95a2-4302-a841-d7235ebacf6e"
      },
      "outputs": [],
      "source": [
        "lena_gray = cv2.cvtColor(lena, cv2.COLOR_BGR2GRAY)\n",
        "imshow(lena_gray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "PiATw8GRuGn9",
        "outputId": "b3e85021-9898-41ba-e0f1-bbc0d070e969"
      },
      "outputs": [],
      "source": [
        "lut = np.array([255] * 100 + [0] * 100 + [255] * 56)\n",
        "lena_lut = cv2.LUT(lena_gray, lut)\n",
        "imshow(lena_lut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RW6mJzYug2k"
      },
      "source": [
        "Biblioteka OpenCV zawiera gotową implementację również innych podejść prostego progowania obrazu. Aby wykonać operację progowania w OpenCV należy wywołać funkcję **threshold()**, która pobiera obraz, wartość progu, wartość maksymalną oraz metodę progowania, która powinna zostać zastosowana.\n",
        "\n",
        "Wśród dostępnych metod progowania są dostępne m.in.:\n",
        "- binary - dla pikseli o intensywnościach poniżej progu przypisana jest wartość **0**, dla pozostałych **wartość maksymalna**,\n",
        "- binary inverted - dla pikseli o intensywnościach poniżej progu przypisana jest wartość **maksymalna**, dla pozostałych **0**,\n",
        "- truncate - dla pikseli o intensywnościach powyżej progu przypisana jest wartość **progu**, pozostałe bez zmian,\n",
        "- to zero - dla pikseli o intensywnościach poniżej progu przypisana jest wartość **0**, pozostałe bez zmian,\n",
        "- to zero inverted - dla pikseli o intensywnościach powyżej progu przypisana jest wartość **0**, pozostałe bez zmian,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "Rypi2Vgp5aJW",
        "outputId": "dfff96d6-56b7-4448-e857-031287d6d1b8"
      },
      "outputs": [],
      "source": [
        "_, lena_bin = cv2.threshold(lena_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "_, lena_bin_inv = cv2.threshold(lena_gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "_, lena_trunc = cv2.threshold(lena_gray, 127, 255, cv2.THRESH_TRUNC)\n",
        "_, lena_tozero = cv2.threshold(lena_gray, 127, 255, cv2.THRESH_TOZERO)\n",
        "_, lena_tozero_inv = cv2.threshold(lena_gray, 127, 255, cv2.THRESH_TOZERO_INV)\n",
        "\n",
        "imshow(np.concatenate([lena_gray, lena_bin, lena_bin_inv], 1))\n",
        "imshow(np.concatenate([lena_trunc, lena_tozero, lena_tozero_inv], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWY22FUZxHCO"
      },
      "source": [
        "Wśród metod progowania można wyróżnić również metody **adaptacyjne.** Sa to metody progowania, które dostosowują wartość progu w zależności od zawartości obrazu.\n",
        "\n",
        "Metody progowania adaptacyjnego działają często bardzo dobrze gdy obraz wejściowy podzieli się na mniejsze obszary a wartość progowania zostanie dla każdego obszaru dostosowana osobno. **Motywacją stojącą za takim mechanizmem jest fakt, że na rzeczywistych obrazach oświetlenie (jak i ostrość, balans, itp.) jest nierównomierny.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "2BCuOjK46AeY",
        "outputId": "5f23a2c2-cf9a-4535-d35f-a105370b3251"
      },
      "outputs": [],
      "source": [
        "lena_ad_mean = cv2.adaptiveThreshold(lena_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 101, 2)\n",
        "lena_ad_gauss = cv2.adaptiveThreshold(lena_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 2)\n",
        "\n",
        "imshow(np.concatenate([lena_ad_mean, lena_ad_gauss], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIrz2xc7zt3G"
      },
      "source": [
        "### Przykład sudoku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "A4nQ4FQkzyDN",
        "outputId": "ace72cfd-6b9b-4210-dbf8-4ad8132cd73a"
      },
      "outputs": [],
      "source": [
        "sudoku = cv2.imread('./sudoku.png', cv2.IMREAD_GRAYSCALE)\n",
        "imshow(sudoku)\n",
        "print(sudoku.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "AWVo0_9iz7GR",
        "outputId": "4edcf152-3c1f-419b-b74d-45b28c7a8b6c"
      },
      "outputs": [],
      "source": [
        "_, sudoku_bin = cv2.threshold(sudoku, 70, 255, cv2.THRESH_BINARY)\n",
        "imshow(sudoku_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "ex8UZhnQ0kVy",
        "outputId": "1d95862b-34c1-4cb8-eb04-00364c5e62fd"
      },
      "outputs": [],
      "source": [
        "lut = np.array([0] * 50 + [255] * 80 + [0] * 126)\n",
        "sudoku_lut = cv2.LUT(sudoku, lut)\n",
        "imshow(sudoku_lut)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "UcmIDI2rz-Qp",
        "outputId": "d8450a43-dc64-4a73-96f4-90c1b24874e7"
      },
      "outputs": [],
      "source": [
        "sudoku_ad_mean = cv2.adaptiveThreshold(sudoku, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 101, 2)\n",
        "sudoku_ad_gauss = cv2.adaptiveThreshold(sudoku, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 2)\n",
        "\n",
        "imshow(np.concatenate([sudoku_ad_mean, sudoku_ad_gauss], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef7_05VS0V-x"
      },
      "source": [
        "### OTSU\n",
        "\n",
        "OTSU to algorytm który adaptacyjnie dobiera taką wartość progu, aby intensywności obu nowych klas (zbinaryzowanych) miały wewnętrzenie najmniejszą wariancję intensywności pikseli (co jest równoznaczne maksymalizacji wariancji międzyklasowej).\n",
        "\n",
        "Minimalizowaną wartością przez OTSU jest:\n",
        "$$\\sigma^2_w(t) = Q_1\\sigma^2_1 + Q_2\\sigma^2_2$$\n",
        "gdzie:\n",
        "- $Q_i$ - prawdopodobieństwo przynależności piksela do klasy i-tej (jest to wartość dystrybuanty, co wynika ze wzoru),\n",
        "$$Q_0 = P(f(x,y) < t_0)$$\n",
        "$$Q_1 = 1 - P(f(x,y) < t_0) $$\n",
        "- $\\sigma^2_i$ - wariancja wewnątrz klasy i-tej.\n",
        "\n",
        "Aby znaleźć najmniejszą wartość wyrażenia można policzyć wszystkie wartości wyrażenia (od 0 do 255).\n",
        "\n",
        "Pierwszym krokiem będzie obliczenie prawdopodobieństwa wystąpienia piksela o danej intensywności (od 0 do 255). Aby takie znaleźć, wystarczy wyznaczyć histogram oraz go znormalizować. Dodatkowo, policzona zostanie dystrybuanta na potrzeby obliczenia średniej i wariancji **warunkowej**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "juNhpiVN5OnK",
        "outputId": "13e60001-9570-431f-f566-b0348b10bd56"
      },
      "outputs": [],
      "source": [
        "def probs(img):\n",
        "  h = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
        "  pdf = h.ravel() / h.sum()\n",
        "  cdf = np.cumsum(pdf)\n",
        "  return pdf, cdf\n",
        "\n",
        "pdf, cdf = probs(sudoku)\n",
        "\n",
        "plt.plot(pdf)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cdf)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdPZ6xxtO1eJ"
      },
      "source": [
        "Pojedyncza iteracja (dla pewnego ustalonego progu) algorytmu OTSU polega na podziale rozkładu prawdopodobieństwa na prawdopodobieństwa wystąpienia pikseli jednej i drugiej klasy. Do wyznaczenia wartości średniej niezbędne jest skorzystanie ze wzoru na **warunkową wartość oczekiwaną** (ponieważ liczymy średnią z pikseli **pod warunkiem**, że zachodzi pewna klasa, lub innymi słowy: ''wartość oczekiwaną dla danej klasy'').\n",
        "\n",
        "Następnie, do wyliczenia wariancji (waunkowych !) korzystamy z wcześniej obliczonych warunkowych wartości oczekiwanych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4Zu1cQf8H7i"
      },
      "outputs": [],
      "source": [
        "def cond_mean(i, p, q):\n",
        "  # conditional expectation: E(X | A) = sum(x * P(x n A)) / P(A)\n",
        "  return (i * p / q).sum()\n",
        "\n",
        "def _otsu(i, pdf, cdf, epsilon=1e-6):\n",
        "  i1, i2 = np.hsplit(np.arange(256), [i])\n",
        "  p1, p2 = np.hsplit(pdf, [i])\n",
        "  q1, q2 = cdf[i], cdf[-1] - cdf[i]\n",
        "\n",
        "  if q1 < epsilon or q2 < epsilon:\n",
        "      return None\n",
        "\n",
        "  m1, m2 = cond_mean(i1, p1, q1), cond_mean(i2, p2, q2)\n",
        "  s1, s2 = cond_mean((i1 - m1) ** 2, p1, q1), cond_mean((i2 - m2) ** 2, p2, q2)\n",
        "\n",
        "  return s1 * q1 + s2 * q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2oi6qy3P1XM"
      },
      "source": [
        "W najbardziej podstawowej wersji algorytm OTSU, jeśli to możliwe, polega na przeiterowaniu wszystkich możliwych podziałów (threshold od 1 do 254) i wybraniu takiego, dla którego wcześniej przedstawiona funkcja celu zwraca najmniejszą wartość."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvBHlVfSLz1f"
      },
      "outputs": [],
      "source": [
        "def otsu(img):\n",
        "  pdf, cdf = probs(img)\n",
        "  v_min = None\n",
        "  threshold = 0\n",
        "\n",
        "  for i in range(1, 256):\n",
        "    v = _otsu(i, pdf, cdf)\n",
        "    if v is not None and (v_min is None or v < v_min):\n",
        "      v_min = v\n",
        "      threshold = i\n",
        "\n",
        "  _, img_otsu = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  return threshold, img_otsu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeWQeJMcQMTd"
      },
      "source": [
        "W celu porównania wyników wykonany został algorytm progowania OTSU korzystając z biblioteki OpenCV (wystarczy dodać flag THRESH_OTSU do operacji progowania)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "OIxQ27c_Kyi-",
        "outputId": "6e786156-2f3a-4873-993f-8acbadf5905a"
      },
      "outputs": [],
      "source": [
        "th_self, sudoku_otsu_self = otsu(sudoku)\n",
        "th_auto, sudoku_otsu_auto = cv2.threshold(sudoku, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "print('Znaleziona wartość progowania algorytmem OTSU (własna implementacja):', th_self)\n",
        "print('Znaleziona wartość progowania algorytmem OTSU (OpenCV):', th_auto)\n",
        "\n",
        "print('\\nOTSU (własna implementacja):')\n",
        "imshow(sudoku_otsu_self)\n",
        "print('\\nOTSU (OpenCV):')\n",
        "imshow(sudoku_otsu_auto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4orNZbe0qek"
      },
      "source": [
        "## Segmentacja obrazów wielokanałowych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0b4bAcl4jN9"
      },
      "source": [
        "Segmentacja obrazów wielokanałowych (np. RGB) prostymi metodami progowania staje się problematyczne ze względu na potrzebę określenia progów w przestrzeni N-wymiarowej. Dlatego zamiast prostego progowania i segmentacji obrazów wielokanałowych częściej stosuje się metody oparte na analizie skupień.\n",
        "\n",
        "Analiza skupień polega na znalezieniu skupisk pikseli w pewnej przestrzeni (nawet bezpośrednio w przestrzeni intensywności!) i utworzeniu w tym otoczeniu odrębnej klasy pikseli.\n",
        "\n",
        "Dla poniższego obrazu przeprowadźmy prostą analizę intensywności pikseli."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "ZawPzbAFRFIN",
        "outputId": "2cbfcc48-07b1-4d0f-f529-7209c0fabfb9"
      },
      "outputs": [],
      "source": [
        "graf = cv2.imread('./graf.png', cv2.IMREAD_COLOR)\n",
        "graf = cv2.resize(graf, None, fx=0.75, fy=0.75)\n",
        "imshow(graf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVtDB8GRoQXI"
      },
      "source": [
        "Obraz przedstawiony jako lista pikseli (BGR) został wyswietlony w przestrzeni 3D, gdzie koordynatami danego piksela są właśnie jego wartości intensywności. Dodatkowo piksele zostały pokolorowane zgodnie z ich intensywnościami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "HqT0-MuqVDAp",
        "outputId": "f142b3f1-4b4b-451b-f8b0-361cc5df0515"
      },
      "outputs": [],
      "source": [
        "graf_pixels = graf.reshape([-1, 3])\n",
        "pix_show(graf_pixels, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rP9LqgcokuT"
      },
      "source": [
        "Z analizy powyższej wizualizacji można wyciągnąć pare wniosków:\n",
        "- większość pikseli leży na prostej pomiędzy kolorem czarnym (0, 0, 0) a białym (255, 255, 255),\n",
        "- można wyróżnić pare skupisk dla kolorów:\n",
        "  - czerwony,\n",
        "  - niebieski,\n",
        "  - złoty,\n",
        "  - zielony,\n",
        "  - bordowy,\n",
        "  - ciemno filoletowy,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xgGxmVypac3"
      },
      "source": [
        "Jedną z metod podziału przestrzeni na klasy jest **Gaussian Mixture**, która polega na przybliżeniu rozkładu skupisk za pomocą N rozkładów gausowskich. Jest to metoda z parametrami uczącymi, dlatego potrzeba jest pewna próba danych, do których moglibyśmy dopasować model matematyczny.\n",
        "\n",
        "Gotowa implementacja algorytmu znajduje się w bibliotece Scikit.\n",
        "\n",
        "Jako dane, do których dopasujemy model wykorzystamy listę pikseli (BGR) a następnie przyporządkujemy każdemu z nich numer roskładu gausowskiego, do którego z największym prawdopodobieństwem należy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlpho8S-Qw4C",
        "outputId": "e977d33a-4415-4fd7-9eb6-1be1376901cc"
      },
      "outputs": [],
      "source": [
        "# inicjalizacja i uczenie modelu\n",
        "model = GaussianMixture(n_components=8)\n",
        "model.fit(graf_pixels)\n",
        "\n",
        "# przypisanie klas do pikseli\n",
        "segments = model.predict(graf_pixels)\n",
        "print(segments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "legLmLOnqZaW"
      },
      "source": [
        "Kolejnym krokiem będzie obliczenie średniego koloru dla każdej z klas (segmentów) i ponowne wyświetlenie pikseli z kolorami reprezentującymi podział na segmenty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "6sIapNyuaflt",
        "outputId": "083c538b-6de0-401a-89c9-f275466563b4"
      },
      "outputs": [],
      "source": [
        "segments_colors = np.stack([graf_pixels[segments==i].mean(0) for i in range(8)], 0)\n",
        "colors = np.take(segments_colors, segments, 0)\n",
        "\n",
        "pix_show(graf_pixels, 16, colors=colors[:, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoSyX_EEqsa3"
      },
      "source": [
        "Piksele z przyporządkowanymi klasami to końcowa segmentacja obrazu na podstawie analizy skupień. Poniżej został przedstawiony obraz wejściowy oraz efekt segmentacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "KyHa5vrVmg58",
        "outputId": "9a6e7fb4-d7be-4430-aee7-531269585779"
      },
      "outputs": [],
      "source": [
        "segmented = colors.reshape(graf.shape)\n",
        "imshow(np.concatenate([graf, segmented], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2MUVx9Z0tWL"
      },
      "source": [
        "## Segmentacja przez wykrywanie krawędzi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhfwPTR74mCl"
      },
      "source": [
        "Segmentacja poprzez wykrywanie krawędzi sprowadza się do wiadomości poznanych na poprzednich zajęciach w ramach wykrywania punktów kluczowych, narożników i krawędzi.\n",
        "\n",
        "Idea polega na podziale obrazu na podstawie krawędzi, a następnie wypełnieniu obszarów zamkniętych przyporządkowując kolejnym separowalnym obszarom następne identyfikatory.\n",
        "\n",
        "Przyporządkowanie obszarom identyfikatorów zostało przedstawione w następnej sekcji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "aAkkcaGyriyD",
        "outputId": "2ea2c20c-d60f-47c7-d6ae-f36f1f1e89ff"
      },
      "outputs": [],
      "source": [
        "clevr = cv2.imread('./clevr.jpg', cv2.IMREAD_COLOR)\n",
        "clevr = cv2.resize(clevr, None, fx=0.5, fy=0.5)\n",
        "imshow(clevr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "QmWRCN5WsBNK",
        "outputId": "ce9ba85a-629e-46c6-b34e-bdd3f9ef4a5d"
      },
      "outputs": [],
      "source": [
        "clevr_gray = cv2.cvtColor(clevr, cv2.COLOR_BGR2GRAY)\n",
        "imshow(clevr_gray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "7oG3fuEQs030",
        "outputId": "4d038e06-1215-463d-91b2-ad7f486ca7ef"
      },
      "outputs": [],
      "source": [
        "canny_high, _ = cv2.threshold(clevr_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "canny_low = 0.5 * canny_high\n",
        "\n",
        "clevr_canny = cv2.Canny(clevr_gray, canny_low, canny_high, 9)\n",
        "clevr_canny = cv2.morphologyEx(clevr_canny, cv2.MORPH_CLOSE, kernel = np.ones((3, 3),np.uint8))\n",
        "imshow(clevr_canny)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNg1Via40yhK"
      },
      "source": [
        "## Segmentacja przez rozrost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stew4GFeutI_"
      },
      "source": [
        "Segmentacja przez rozrost polega na iteracyjnym łączeniu przyległych ze sobą obszarów tak długo, aż nie zostanie spełniony pewien warunek. Łączenie obszarów następuje po spełnieniu **testu jednolitości**, natomiast algorytm wykonuje się tak długo aż zostanie spełniony **warunek stopu**.\n",
        "\n",
        "**Test jednolitości** - polega na połączeniu rozważanych obszarów i sprawdzeniu pewnego warunku. Jako warunek można przyjąć np. różnicę średniej intensywności pikseli w obu obszarach. Jeśli jest większa niż pewien próg, wówczas obszary nie są jednolite i nie zachodzi połączenie.\n",
        "\n",
        "**Warunek stopu** - warunek ten można traktować jako brak kolejnych scaleń obszarów lub jako warunek wczesnego zatrzymania algorytmu (np. gdy chcemy aby obszary nie były większe niż ustalony limit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "4xcBTPqoxZZ3",
        "outputId": "3016e26e-cec4-43c1-938f-22901a87b0f5"
      },
      "outputs": [],
      "source": [
        "regions = np.zeros(clevr_canny.shape[:2], np.int32)\n",
        "neighbours = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
        "\n",
        "def find_neighbours(img, y, x):\n",
        "  c_neighbours = []\n",
        "  for dy, dx in neighbours:\n",
        "    ny, nx = y + dy, x + dx\n",
        "\n",
        "    if ny < 0 or ny >= img.shape[0] or nx < 0 or nx >= img.shape[1]:\n",
        "      continue\n",
        "\n",
        "    if regions[ny, nx] > 0:\n",
        "      continue\n",
        "\n",
        "    if img[ny, nx] == 255:\n",
        "      continue\n",
        "\n",
        "    if img[y, x] == img[ny, nx]:\n",
        "      c_neighbours.append((ny, nx))\n",
        "\n",
        "  return c_neighbours\n",
        "\n",
        "\n",
        "def grow_region(img, y, x, cls):\n",
        "  regions[y, x] = cls\n",
        "\n",
        "  c_neighbours = find_neighbours(img, y, x)\n",
        "  for ny, nx in c_neighbours:\n",
        "      regions[ny, nx] = cls\n",
        "\n",
        "  while len(c_neighbours) > 0:\n",
        "    new_neighbours = []\n",
        "    for ny, nx in c_neighbours:\n",
        "      i_new_neighbours = find_neighbours(img, ny, nx)\n",
        "      for _ny, _nz in i_new_neighbours:\n",
        "        regions[_ny, _nz] = cls\n",
        "\n",
        "      new_neighbours.extend(i_new_neighbours)\n",
        "\n",
        "    c_neighbours = new_neighbours\n",
        "\n",
        "\n",
        "i = 1\n",
        "for y in range(clevr_canny.shape[0]):\n",
        "  for x in range(clevr_canny.shape[1]):\n",
        "    if regions[y, x] == 0 and clevr_canny[y, x] == 0:\n",
        "      grow_region(clevr_canny, y, x, i)\n",
        "      i += 1\n",
        "\n",
        "mean_colors = np.stack([np.array([255, 255, 255]) if j == 0 else clevr[regions==j].mean(0) for j in range(i)], 0)\n",
        "regions_colors = np.take(mean_colors, regions, 0)\n",
        "\n",
        "imshow(regions_colors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB4CzX1W0vSA"
      },
      "source": [
        "# Zadania"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uItcZviK07i3"
      },
      "source": [
        "## Zadanie 1\n",
        "\n",
        "Na wzór sekcji o segmentacji obrazów wielokanałowych, przeprowadź taką samą analizę skupień intensywności pikseli dla obrazu './skittles.jpg' a następnie posegmentuj obraz korzystając z algorytmu K-Means (dostępnego m.in. w bibliotece scikit: sklearn.cluster.KMeans).\n",
        "\n",
        "Przedstaw wyniki pośrednie:\n",
        "- obraz wejściowy BGR\n",
        "- piksele BGR w przestrzeni 3D,\n",
        "- wynik segmentacji na pikselach BGR w przestrzeni 3D,\n",
        "- wynik segmentacji jako obraz 2D (BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# obraz wejściowy BGR\n",
        "skittles = cv2.imread('./skittles.jpg')\n",
        "imshow(skittles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# piksele BGR w przestrzeni 3D\n",
        "skittles_pixels = skittles.reshape([-1, 3])\n",
        "pix_show(skittles_pixels, 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "model = KMeans(5)\n",
        "model.fit(skittles_pixels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wynik segmentacji na pikselach BGR w przestrzeni 3D\n",
        "segments = model.predict(skittles_pixels)\n",
        "segments_colors = np.stack([skittles_pixels[segments==i].mean(0) for i in range(5)], 0)\n",
        "colors = np.take(segments_colors, segments, 0)\n",
        "\n",
        "pix_show(skittles_pixels, 16, colors=colors[:, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wynik segmentacji jako obraz 2D (BGR)\n",
        "segmented = colors.reshape(skittles.shape)\n",
        "imshow(np.concatenate([skittles, segmented], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZcA4bcC09Hw"
      },
      "source": [
        "## Zadanie 2\n",
        "\n",
        "Korzystając z metod progowania/segmentacji i znanych operacji morfologicznych, znajdź liczbę skittlesów na obrazie './skittles.jpg'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QluLi6eZ1LZW"
      },
      "outputs": [],
      "source": [
        "skittles = cv2.imread('./skittles.jpg')\n",
        "skittles_gray = cv2.cvtColor(skittles, cv2.COLOR_BGR2GRAY)\n",
        "# skittles_high, _ = cv2.threshold(skittles_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "# skittles_low = 0.5 * skittles_high\n",
        "\n",
        "skittles_canny = cv2.Canny(skittles_gray, 100, 200)\n",
        "skittles_canny = cv2.dilate(skittles_canny, (1, 1), iterations=5)\n",
        "# skittles_canny = cv2.erode(skittles_canny, (1, 1), iterations=1)\n",
        "skittles_canny = cv2.morphologyEx(skittles_canny, cv2.MORPH_CLOSE, kernel = np.ones((3, 3),np.uint8))\n",
        "imshow(skittles_canny)\n",
        "\n",
        "contours, _ = cv2.findContours(skittles_canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = list(filter(lambda x: x.max() - x.min() > 500, contours))\n",
        "\n",
        "cv2.drawContours(skittles, contours, -1, (0, 255, 0), 2)\n",
        "imshow(skittles)\n",
        "print(len(contours))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
