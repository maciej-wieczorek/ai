{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_r0j8Xuqsga"
      },
      "source": [
        "# Widzenie komputerowe - Laboratoria nr 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVWBS5p-r5j9"
      },
      "source": [
        "## Opis laboratoriów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2FzMMMr9kr"
      },
      "source": [
        "\n",
        "\n",
        "* obraz w dziedzinie częstotliwości,\n",
        "* analiza obrazu w dziedzinie częstotliwości,\n",
        "* filtrowanie górno- oraz dolno-przepustowe,\n",
        "* optymalizacja procesu filtrowania za pomocą operacji splotu korzystając z dziedziny częstotliwości"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJXpBTXtET5"
      },
      "source": [
        "## Funkcje pomocnicze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du-h1aTru9ES"
      },
      "source": [
        "Do wykonania zadań niezbędne jest zaimportowanie bibliotek, wykorzystywanych w skrypcie oraz pobranie danych, na których przetwarzane będą operacje.\n",
        "\n",
        "W skrypcie wykorzystywane będą dwa zestawy danych:\n",
        "* obraz Lenna (dostępny pod [linkiem](http://www.lenna.org/)) - jeden z najbardziej popularnych obrazów wykorzystywanych historycznie do kompresji i przetwarzania obrazów,\n",
        "* \"Bug Challenge\" - zestaw zdjęć mrówki, zrobione z ostrością ustawioną na co raz dalsze fragmenty od obiektywu (dostępny pod [linkiem](http://grail.cs.washington.edu/projects/photomontage/))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTvT7icdtMZY"
      },
      "outputs": [],
      "source": [
        "# import niezbędnych bibliotek\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "%matplotlib inline\n",
        "from pandas import DataFrame\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "from skimage.exposure import rescale_intensity\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "pd.options.display.html.border = 0\n",
        "pd.options.display.float_format = '{:,.2f}'.format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV4aWjegtCKx",
        "outputId": "2e6f1733-0424-4cb3-8a39-94cca55b7630"
      },
      "outputs": [],
      "source": [
        "# pobranie niezbędnych bibliotek\n",
        "!wget -O lena_std.tif http://www.lenna.org/lena_std.tif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUIRaE_UwVOx"
      },
      "source": [
        "Ze względu na problem z wyświetlaniem obrazów przez bibliotekę OpenCV w środowisku Colab, w przypadku korzystania z tej platformy należy skorzystać z funkcji specjalnie do tego przygotowanej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCHL_RVqunsJ"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  imshow = cv2_imshow\n",
        "else:\n",
        "  def imshow(a):\n",
        "    a = a.clip(0, 255).astype('uint8')\n",
        "    if a.ndim == 3:\n",
        "      if a.shape[2] == 4:\n",
        "        a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "      else:\n",
        "        a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "    display(PIL.Image.fromarray(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSPs8nInQXUu"
      },
      "outputs": [],
      "source": [
        "def h_color(a, interpolation=None, size=None, fy=1.5, fx=1.5, cmap='gray'):\n",
        "  s = [int(a.shape[0] * fy), int(a.shape[1] * fx)] if size is None else size\n",
        "  plt.figure(figsize=s)\n",
        "  plt.tick_params(\n",
        "    axis='both', which='both',\n",
        "    bottom=False, top=False,\n",
        "    labelbottom=False, labelleft=False, left=False, right=False\n",
        "  )\n",
        "  plt.imshow(a, cmap=cmap, interpolation=interpolation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE_drKEIQYjA"
      },
      "outputs": [],
      "source": [
        "css = \"\"\"\n",
        "<style type=\"text/css\">\n",
        "  table, td, table.dataframe, table.dataframe td {\n",
        "    border: 1px solid black;    //border: double;\n",
        "    border-collapse: collapse;\n",
        "    border-style: solid;\n",
        "    border-spacing: 0px;\n",
        "    background-color: rgb(250,250,250);\n",
        "    width: 24px;\n",
        "    height: 24px;\n",
        "    text-align: center;\n",
        "    transform: scale(1.0);\n",
        "    margin: 5px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "def h(s):\n",
        "   return display(HTML(css + DataFrame(s).to_html(header=False, index=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkmCwTvhQaBG"
      },
      "outputs": [],
      "source": [
        "def h_color_3d(z):\n",
        "  fig = go.Figure(data=[go.Surface(z=z)])\n",
        "  fig.update_layout(autosize=False, width=500, height=500)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ae_-TgIzbKs"
      },
      "source": [
        "# Obraz w dziedzinie częstotliwości"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j8Nr5jhI03e"
      },
      "source": [
        "Powyższe przykłady przetwarzania obrazów dotyczyły dziedziny intensywności. Inną dziedziną, w której można reprezentować obraz, jest **częstotliwość**. Obraz w dziedzinie częstotliwości należy traktować jako informacje które piksele zawierają jakiś powtarzający się schemat, a które są mało powtarzającymi się wzorami.\n",
        "\n",
        "Przykładowo, obraz bardzo rozmazany, będzie posiadał rzadko powtarzające się wzorce (a które zajmują rozległy obszar obrazu), natomiast dla obrazu bardzo dokładnego wzorce te będą o wiele częściej się powtarzać i dotyczyć będą wyszczególnionych obszarów obrazu.\n",
        "\n",
        "Poniżej zaprezentowany został przykład przejścia z dziedziny intensywności do dziedziny częstotliwości."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "j89mQEaqQjC6",
        "outputId": "3fdd24fa-ccc8-4bad-d69a-4a0730a07b0f"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('./lena_std.tif', 1)\n",
        "img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUUWiXtVABSc"
      },
      "source": [
        "Operację przejścia z dziedziny intensywności do dziedziny częstotliwości można wykonać za pomocą implementacji w OpenCV lub tej dostępnej w bibliotece NumPy. Poniżej zaprezentowany został przykład użycia biblioteki NumPy.\n",
        "\n",
        "Funkcja **fft2** wykonuje Transformatę Fouriera dla sygnałów 2-wymiarowych. Następnie, korzystając z funkcji **fftshift** przesuwamy dane w ten sposób, aby piksele odpowiadające **niskim częstotliwościom** znajdowały się bliżej środka a piksele **wysokich częstotliwości** na krańcach obrazu (w dziedzinie częstotliwości).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrffH9q9rdrS"
      },
      "outputs": [],
      "source": [
        "f = np.fft.fft2(img_grayscale)\n",
        "fshift = np.fft.fftshift(f)\n",
        "magnitude_spectrum = 20 * np.log(np.abs(fshift))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkozDxHBVCM"
      },
      "source": [
        "Otwrotna transformata sprowadza się do wykonania odwrotnego przesunięcie pikseli oraz wykonania operacji **ifft2**, której wynikiem jest obraz w dziedzinie intensywności (w postaci liczby zespolonej, stąd dodatkowe pobranie części rzeczywistej - **real()**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "s_K5-2JTBTRp",
        "outputId": "32224d47-74a1-4ee6-d593-5acd4827b244"
      },
      "outputs": [],
      "source": [
        "f_ishift = np.fft.ifftshift(fshift)\n",
        "img_back = np.fft.ifft2(f_ishift)\n",
        "img_back = np.real(img_back)\n",
        "\n",
        "imshow(np.concatenate([img_grayscale, magnitude_spectrum, img_back], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxqlDehuLq9L"
      },
      "source": [
        "### Transformata Fouriera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L3GyQM4LxWO"
      },
      "source": [
        "Transformata Fouriera określona jest następującym wzorem:\n",
        "\n",
        "$${\\mathcal{F}}(\\omega) = \\int_{-\\infty}^{\\infty} f(x) e^{-2\\pi i x \\omega} dx$$\n",
        "\n",
        "Gdzie $\\omega$ to częstotliwości omawiane w powyższych przykładach, $f(x)$ obraz w skali intensywności, $i^2 = -1$ - liczba urojona. Powyższy wzór można interpretować następująco:\n",
        "\n",
        "* ${\\mathcal{F}}(\\omega)$ wykonywana jest dla każdej częstotliwości (może to być określony z góry przedział lub tak jak w przypadku domyślnej implementacji w numpy częstotliwości z zakresu $<-S_h, S_h>$ oraz $<-S_w, S_w>$, a więc $\\omega$ jest dowolną parą utworzoną z tych zakresów),\n",
        "* dla każdego wywołania ${\\mathcal{F}}(\\omega)$ wykonywane jest przemnożenie obrazu wejściowego przez składnik podany we wzorze (z odpowiednim $\\omega$) i sumowanie otrzymanego elementu. Można to również traktować jako sumę ważoną każdego piksela, gdzie wagą jest podany we wzorze składnik,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_6431JtN1RO"
      },
      "source": [
        "## Interpretacja dziedziny częstotliwości"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZY446pMKYSO"
      },
      "source": [
        "Wiedząc jak wykonać transformatę odwrotną (częstotliwość -> intensywność), możemy wykonać pare eksperymentów, aby przybliżyć zależność pomiędzy wartościami pikseli w dziedzinie częstotliwości a intensywności."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p62DD-Fque6"
      },
      "outputs": [],
      "source": [
        "def get_mask(s, div):\n",
        "    mask = np.zeros(s, np.float32)\n",
        "    return cv2.circle(mask,(s[0]//2, s[1]//2), s[0]//div, 1, -1)\n",
        "\n",
        "def fft(img, size=None):\n",
        "    f = np.fft.fft2(img, size)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    spectrum = 20 * np.log(np.abs(fshift))\n",
        "    return fshift, spectrum\n",
        "\n",
        "def ifft(fshift):\n",
        "    f_ishift = np.fft.ifftshift(fshift)\n",
        "    img_back = np.fft.ifft2(f_ishift)\n",
        "    return np.real(img_back)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfE_Aw6YqpfJ"
      },
      "source": [
        "Zdefiniujmy obraz (256 x 256) wypełniony samymi zerami z ustawionymi wysokimi wartościami na określonych pozycjach. Pozycjami tymi będą odpowiednio (gdzie $S_h = height / 2 = 128$ oraz $S_w = width / 2 = 128$):\n",
        "\n",
        "* $(S_h, S_w)$\n",
        "* $(S_h, S_w - 1)$\n",
        "* $(S_h, S_w + 1)$\n",
        "* $(S_h, S_w - 1)$, $(S_h, S_w + 1)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "SVrOOH39KwcP",
        "outputId": "9529e4a9-32b3-4a12-8fb5-70b10e1becdd"
      },
      "outputs": [],
      "source": [
        "sw = 256 // 2\n",
        "sh = 256 // 2\n",
        "\n",
        "freq_1 = np.zeros([256, 256], np.float32)\n",
        "freq_1[sh, sw] = 10000000.0\n",
        "\n",
        "freq_2 = np.zeros([256, 256], np.float32)\n",
        "freq_2[sh, sw - 1] = 10000000.0\n",
        "\n",
        "freq_3 = np.zeros([256, 256], np.float32)\n",
        "freq_3[sh, sw + 1] = 10000000.0\n",
        "\n",
        "freq_4 = np.zeros([256, 256], np.float32)\n",
        "freq_4[sh, sw - 1] = 10000000.0\n",
        "freq_4[sh, sw + 1] = 10000000.0\n",
        "\n",
        "\n",
        "img_i_1 = ifft(freq_1)\n",
        "img_i_2 = ifft(freq_2)\n",
        "img_i_3 = ifft(freq_3)\n",
        "img_i_4 = ifft(freq_4)\n",
        "\n",
        "imshow(np.concatenate([freq_1, freq_2, freq_3, freq_4], 1))\n",
        "imshow(np.concatenate([img_i_1, img_i_2, img_i_3, img_i_4], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrPaM_w7DQmx"
      },
      "source": [
        "Analogicznie dla zmian wartości pikseli wertykalnie:\n",
        "* $(S_h, S_w)$\n",
        "* $(S_h - 1, S_w)$\n",
        "* $(S_h + 1, S_w)$\n",
        "* $(S_h - 1, S_w)$, $(S_h + 1, S_w)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "sifKYV_tDL85",
        "outputId": "bac58c69-dc7e-4c8f-cc5a-4578984e865b"
      },
      "outputs": [],
      "source": [
        "sw = 256 // 2\n",
        "sh = 256 // 2\n",
        "\n",
        "freq_1 = np.zeros([256, 256], np.float32)\n",
        "freq_1[sh, sw] = 10000000.0\n",
        "freq_2 = np.zeros([256, 256], np.float32)\n",
        "freq_2[sh - 1, sw] = 10000000.0\n",
        "freq_3 = np.zeros([256, 256], np.float32)\n",
        "freq_3[sh + 1, sw] = 10000000.0\n",
        "freq_4 = np.zeros([256, 256], np.float32)\n",
        "freq_4[sh - 1, sw] = 10000000.0\n",
        "freq_4[sh + 1, sw] = 10000000.0\n",
        "\n",
        "\n",
        "img_i_1 = ifft(freq_1)\n",
        "img_i_2 = ifft(freq_2)\n",
        "img_i_3 = ifft(freq_3)\n",
        "img_i_4 = ifft(freq_4)\n",
        "\n",
        "imshow(np.concatenate([freq_1, freq_2, freq_3, freq_4], 1))\n",
        "imshow(np.concatenate([img_i_1, img_i_2, img_i_3, img_i_4], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtJGS3jYMUIm"
      },
      "source": [
        "Powyższy eksperyment dostarcza następujące wskazówki:\n",
        "* środkowy piksel odpowiada jednolitemu obrazowi (częstotliwość równa zero),\n",
        "* piksele odchylone o 1 na lewo i prawo reprezentują te same wyniki, ponieważ odpowiadają im sygnały o przeciwnych częstotliwościach),\n",
        "* odchylenia horyzontalne odpowiadają horyzontalnym sygnałom 2D na obrazie w dziedzinie intensywności; analogicznie dla wertykalnych odchyleń.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCrZl2nbHc7a"
      },
      "source": [
        "Ustawiając wysokie wartości dalej od środka operacja odwrotnej transformaty fouriera utworzy obrazy w dziedzinie intensywności zawierające sygnały o większej częstotliwości."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "dFZ7V1B_NE3o",
        "outputId": "3f27a489-d281-4914-9a4b-d228ad1377e7"
      },
      "outputs": [],
      "source": [
        "sw = 256 // 2\n",
        "sh = 256 // 2\n",
        "\n",
        "freq_1 = np.zeros([256, 256], np.float32)\n",
        "freq_1[sh - 1, sw] = 10000000.0\n",
        "freq_1[sh + 1, sw] = 10000000.0\n",
        "freq_1[sh, sw - 1] = 10000000.0\n",
        "freq_1[sh, sw + 1] = 10000000.0\n",
        "freq_2 = np.zeros([256, 256], np.float32)\n",
        "freq_2[sh - 1, sw - 1] = 10000000.0\n",
        "freq_2[sh + 1, sw + 1] = 10000000.0\n",
        "freq_2[sh - 1, sw + 1] = 10000000.0\n",
        "freq_2[sh + 1, sw - 1] = 10000000.0\n",
        "freq_3 = np.zeros([256, 256], np.float32)\n",
        "freq_3[sh, sw - 2] = 10000000.0\n",
        "freq_4 = np.zeros([256, 256], np.float32)\n",
        "freq_4[sh, sw - 8] = 10000000.0\n",
        "\n",
        "img_i_1 = ifft(freq_1)\n",
        "img_i_2 = ifft(freq_2)\n",
        "img_i_3 = ifft(freq_3)\n",
        "img_i_4 = ifft(freq_4)\n",
        "\n",
        "imshow(np.concatenate([freq_1, freq_2, freq_3, freq_4], 1))\n",
        "imshow(np.concatenate([img_i_1, img_i_2, img_i_3, img_i_4], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP9Dk7nSN8x6"
      },
      "source": [
        "## Operacje w dziedzinie częstotliwości"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfdj6XDfI4Aa"
      },
      "source": [
        "Przetwarzanie obrazu w dziedzinie częstotliwości jest ściśle związane z pojęciem konwolucji w dziedzinie intensywności. Zgodnie z twierdzeniem wynikającym z postaci transformaty Fouriera ([link](https://en.wikipedia.org/wiki/Convolution_theorem)) możemy zapisać:\n",
        "\n",
        "$$(f \\ast g)(t) = {\\mathcal{F}}^{-1}\\{F \\cdot G\\}$$\n",
        "\n",
        "gdzie:\n",
        "* $f$, $F$ - obraz wejściowy odpowiednio w dziedzinie intensywności i częstotliwości,\n",
        "* $g$, $G$ - kernel/filtr (np. Laplasjan) odpowiednio w dziedzinie intensywności i częstotliwości,\n",
        "* ${\\mathcal{F}^{-1}}$ - odwrotna transformata Fouriera\n",
        "\n",
        "Powyższa teoria mówi, że operacja konwolucji dwóch funkcji w dziedzinie czasu lub przestrzeni jest równoznaczna z operacją mnożenia **(element-wise)** ich reprezentacji w przestrzeni częstotliwości.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkSgRL2ftJPE"
      },
      "source": [
        "Wcześniejsze transformacje pomiędzy dziedzinami pokazały, że obraz o pewnym rozmiarze (intensywność) będzie miał ten sam rozmiar w dziedzinie częstotliwości. Rozmiar bezpośrednio wpływa liczbę maksymalnych częstotliwości, stąd aby zaprezentować obraz o mniejszym rozmiarze w większej liczbie częstotliwości **można obraz uzupełnić (jak przy konwolucji) samymi zerami**.\n",
        "\n",
        "Korzystając z implementacji w OpenCV należy zrobić to ręcznie, natomiast przy implementacji NumPy, wystarczy dodać informacje o rozmiarze jako drugi parametr funkcji fft2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "0esU8e6NtO_m",
        "outputId": "738bb844-8393-462a-efe8-c075302dea82"
      },
      "outputs": [],
      "source": [
        "mean_filter = np.ones((3,3))\n",
        "\n",
        "x = cv2.getGaussianKernel(5,10)\n",
        "gaussian = x*x.T\n",
        "\n",
        "laplacian = np.array([[0, 1, 0],\n",
        "                    [1,-4, 1],\n",
        "                    [0, 1, 0]])\n",
        "\n",
        "\n",
        "filters = [mean_filter, gaussian, laplacian]\n",
        "fft_filters = [np.fft.fft2(x, (256, 256)) for x in filters]\n",
        "fft_shift = [np.fft.fftshift(y) for y in fft_filters]\n",
        "mag_spectrum = [np.log(np.abs(z)+1) for z in fft_shift]\n",
        "\n",
        "imshow(np.concatenate(mag_spectrum, 1) * 255)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g5LfZXGtSWv"
      },
      "source": [
        "Posiadając obrazy w tej samej dziedzinie określonej tą samą liczbą częstotliwości, zgodnie z przytoczoną teorią, możemy wykonać odpowiednik operacji konwolucji korzystając z prostego mnożenia w dziedzinie intensywności."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "soMEjDAOzytX",
        "outputId": "e1194054-c81c-4b41-f7a3-6dca9cfdf3ec"
      },
      "outputs": [],
      "source": [
        "\n",
        "laplacian=np.array([[0, 1, 0],\n",
        "                    [1,-4, 1],\n",
        "                    [0, 1, 0]])\n",
        "\n",
        "# intensity\n",
        "f_lap_shift, f_lap_mag = fft(laplacian, (512, 512))\n",
        "fshift, spectrum = fft(img_grayscale)\n",
        "img_i = ifft(fshift * f_lap_shift)\n",
        "\n",
        "imshow(np.concatenate([img_grayscale, spectrum * f_lap_shift, img_i], 1))\n",
        "\n",
        "img_i = cv2.filter2D(img_grayscale, -1, laplacian)\n",
        "imshow(np.concatenate([img_grayscale, img_i], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PB18WvmIur-"
      },
      "source": [
        "### Filtr dolnoprzepustowy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwV5PTpRyEg4"
      },
      "source": [
        "Filtrowanie w dziedzinie częstotliwości możemy również podzielić na dolnoprzepustowe i górnoprzepustowe.\n",
        "\n",
        "Filtrowanie dolnoprzepustowe to takie, które przepuszcza sygnały o małej częstotliwości i ucina sygnały powyżej pewnego progu. Jak wiadomo, sygnały o wysokiej częstotliwości znajdują się na krańcach obrazu, a im bliżej środka, tym sygnały posiadają mniejszą częstotliwość.\n",
        "\n",
        "Poniżej zostało przedstawione filtrowanie dolnoprzepustowe zrealizowane jako próg odcięcia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8KciZeWir7Pd",
        "outputId": "d7cdcb85-e584-4b97-8bb3-a0db820e6d7b"
      },
      "outputs": [],
      "source": [
        "m1 = get_mask(img_grayscale.shape, 2)\n",
        "m2 = get_mask(img_grayscale.shape, 8)\n",
        "m3 = get_mask(img_grayscale.shape, 16)\n",
        "\n",
        "fshift, spectrum = fft(img_grayscale)\n",
        "\n",
        "img_back_1 = ifft(fshift * m1)\n",
        "img_back_2 = ifft(fshift * m2)\n",
        "img_back_3 = ifft(fshift * m3)\n",
        "\n",
        "imshow(np.concatenate([img_grayscale, spectrum * m1, img_back_1], 1))\n",
        "imshow(np.concatenate([img_grayscale, spectrum * m2, img_back_2], 1))\n",
        "imshow(np.concatenate([img_grayscale, spectrum * m3, img_back_3], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-eT7MQxztGY"
      },
      "source": [
        "Rezultatem działania filtrów dolnoprzepustowych zazwyczaj powinien być efekt rozmycia ze względu na fakt, że pozbywamy się obszarów o dużej zmienności (jak np. krawędzie, szczególy ale również szum).\n",
        "\n",
        "**UWAGA: FFT może idealnie sprawdzić się jako kompresja danych.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YykI8ffjIuxm"
      },
      "source": [
        "### Filtr górnoprzepustowy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fApaKwStz9sp"
      },
      "source": [
        "Analogicznie działają filtry z rodziny górnoprzepustowych. Przepuszczając sygnały o tylko dużej częstotliwości dokonujemy ekstrakcji miejsc, gdzie są krawędzie, duża ostrość obrazu lub po prostu szum.\n",
        "\n",
        "Poniżej zaprezentowano filtr górnoprzepustowy zrealizowany jako odcięcie sygnałów poniżej pewnego progu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4whoyhSRstBB",
        "outputId": "0e696c87-988a-424b-c33d-00e900223fc5"
      },
      "outputs": [],
      "source": [
        "m1 = 1 - get_mask(img_grayscale.shape, 2)\n",
        "m2 = 1 - get_mask(img_grayscale.shape, 16)\n",
        "m3 = 1 - get_mask(img_grayscale.shape, 32)\n",
        "\n",
        "fshift, spectrum = fft(img_grayscale)\n",
        "\n",
        "img_back_1 = ifft(fshift * m1)\n",
        "img_back_2 = ifft(fshift * m2)\n",
        "img_back_3 = ifft(fshift * m3)\n",
        "\n",
        "imshow(np.concatenate([img_grayscale, spectrum * m1, img_back_1], 1))\n",
        "imshow(np.concatenate([img_grayscale, spectrum * m2, img_back_2], 1))\n",
        "imshow(np.concatenate([img_grayscale, spectrum * m3, img_back_3], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHm8EdBh1MKT"
      },
      "source": [
        "# Zadania"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wect3PYP1Nfg"
      },
      "source": [
        "## Zadanie 1\n",
        "\n",
        "Sprawdź i uargumentuj, który z niżej wypisanych filtrów jest dolnoprzepustowy, a który górnoprzepustowy.\n",
        "\n",
        "Filtry:\n",
        "* uśredniający,\n",
        "* gaussowski,\n",
        "* sobel,\n",
        "* laplasjan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2ibSgMT1bJJ"
      },
      "outputs": [],
      "source": [
        "def get_mag_spect(img):\n",
        "    f = np.fft.fft2(img)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    return 20 * np.log(np.abs(fshift))\n",
        "\n",
        "def show_with_spectrum(img):\n",
        "    imshow(np.concatenate([img, get_mag_spect(img)], 1))\n",
        "\n",
        "show_with_spectrum(img_grayscale)\n",
        "show_with_spectrum(cv2.blur(img_grayscale, (5,5))) # dolno\n",
        "show_with_spectrum(cv2.GaussianBlur(img_grayscale, (5,5), 3)) # dolno\n",
        "show_with_spectrum(cv2.Sobel(img_grayscale, cv2.CV_64F, 0, 1, ksize=3)) # górno\n",
        "show_with_spectrum(cv2.Laplacian(img_grayscale, cv2.CV_64F, ksize=3)) # górno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjENldc92CNb"
      },
      "source": [
        "## Zadanie 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4FutrEg2EOJ"
      },
      "source": [
        "Wykonaj detekcję krawędzi (osobno pionowo i poziomo) korzystając z filtrów Sobela w dziedzinie częstotliwości, następnie połącz wykryte cechy do jednego obrazu i zaprezentuj wyniki. Działanie w dziedzinie częstotliwości porównaj z działaniem filtru Sobela w dziedzinie intensywności."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC6g03V12TYA"
      },
      "outputs": [],
      "source": [
        "def combine_sobel(h, v):\n",
        "    return cv2.max(h, v)\n",
        "\n",
        "sobel_h=np.array([[1, 2, 1],\n",
        "                  [0, 0, 0],\n",
        "                  [-1, -2, -1]])\n",
        "\n",
        "sobel_v=np.array([[1, 0, -1],\n",
        "                  [2, 0, -2],\n",
        "                  [1, 0, -1]])\n",
        "\n",
        "fshift, spectrum = fft(img_grayscale)\n",
        "\n",
        "f_sobel_h_shift, _ = fft(sobel_h, (512, 512))\n",
        "f_sobel_v_shift, _ = fft(sobel_v, (512, 512))\n",
        "\n",
        "\n",
        "img_i_h = ifft(fshift * f_sobel_h_shift)\n",
        "img_i_v = ifft(fshift * f_sobel_v_shift)\n",
        "\n",
        "imshow(np.concatenate([combine_sobel(img_i_h, img_i_v),\n",
        "                       combine_sobel(cv2.Sobel(img_grayscale, cv2.CV_64F, 0, 1, ksize=3), cv2.Sobel(img_grayscale, cv2.CV_64F, 1, 0, ksize=3))\n",
        "                       ], 1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WMJXpBTXtET5"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
