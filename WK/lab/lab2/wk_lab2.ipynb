{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm8rnvOON4Zy"
      },
      "source": [
        "![](./logo.png)*„Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”,\n",
        "projekt finansowany ze środków Programu Operacyjnego Polska Cyfrowa POPC.03.02.00-00-0001/20*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_r0j8Xuqsga"
      },
      "source": [
        "# Widzenie komputerowe\n",
        "# Moduł laboratoryjny 1, Laboratoria 1 i 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVWBS5p-r5j9"
      },
      "source": [
        "## Opis laboratoriów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2FzMMMr9kr"
      },
      "source": [
        "\n",
        "\n",
        "*   Wprowadzenie do przetwarzania obrazów\n",
        "*   Wizualizacja obrazów,\n",
        "*   Reprezentacja obrazów w różnych przestrzeniach barw i dziedzinach,\n",
        "*   Transformacje jednopunktowe Obraz -> Obraz,\n",
        "*   Arytmetyka obrazowa i przykładowe zastosowanie,\n",
        "*   Transformacje geometryczne\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJXpBTXtET5"
      },
      "source": [
        "## Funkcje pomocnicze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du-h1aTru9ES"
      },
      "source": [
        "Do wykonania zadań niezbędne jest zaimportowanie bibliotek, wykorzystywanych w skrypcie oraz pobranie danych, na których przetwarzane będą operacje.\n",
        "\n",
        "W skrypcie wykorzystywane będą dwa zestawy danych:\n",
        "* obraz Lenna (dostępny pod [linkiem](http://www.lenna.org/)) - jeden z najbardziej popularnych obrazów wykorzystywanych historycznie do kompresji i przetwarzania obrazów,\n",
        "* \"Bug Challenge\" - zestaw zdjęć mrówki, zrobione z ostrością ustawioną na co raz dalsze fragmenty od obiektywu (dostępny pod [linkiem](http://grail.cs.washington.edu/projects/photomontage/))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XTvT7icdtMZY"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pil'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpil\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pil'"
          ]
        }
      ],
      "source": [
        "# import niezbędnych bibliotek\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pil\n",
        "from ipython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV4aWjegtCKx",
        "outputId": "1a928b42-e2ae-432e-a542-93d311a36290"
      },
      "outputs": [],
      "source": [
        "# pobranie niezbędnych bibliotek\n",
        "!wget -O lena_std.tif http://www.lenna.org/lena_std.tif\n",
        "!wget -O bug.zip http://grail.cs.washington.edu/projects/photomontage/data/bug.zip && unzip -o bug.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUIRaE_UwVOx"
      },
      "source": [
        "Ze względu na problem z wyświetlaniem obrazów przez bibliotekę OpenCV w środowisku Colab, w przypadku korzystania z tej platformy należy skorzystać z funkcji specjalnie do tego przygotowanej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCHL_RVqunsJ"
      },
      "outputs": [],
      "source": [
        "def imshow(a):\n",
        "  a = a.clip(0, 255).astype('uint8')\n",
        "  if a.ndim == 3:\n",
        "    if a.shape[2] == 4:\n",
        "      a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "    else:\n",
        "      a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "  display(PIL.Image.fromarray(a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NDxyewRrEOb"
      },
      "source": [
        "# Przestrzenie barw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlKSPgZZQDyI"
      },
      "source": [
        "Cyfrowe przechowywanie obrazów polega na reprezentacji koloru w pewnej dziedzinie, która w pewnym stopniu odzwierciedla to, jak człowiek postrzega światło. Najbardziej intuicyjną dziedziną jest **intensywność**, w której obraz składa się z pikseli ułożonych w postaci macierzy 2D. Każdy z pikseli posiada swoją **wartość intensywności**. Tę wartość można przedstawić na wiele sposobów, np.:\n",
        "\n",
        "* RGB - jakos 3 wartości określające stopień nasycenia kolorami Red, Green, Blue,\n",
        "* CMYK - analogicznie, Cyan, Magenta, Yellow, Black (Key color),\n",
        "* HSV - Hue (odcień koloru), Saturation (nasycenie), Value (lub Brightness - jasność koloru),\n",
        "* Grayscale - odcień szarości,\n",
        "\n",
        "Różne przestrzenie barw dostarczają różnych możliwości przetwarzania obrazu. Przykładowo z przestrzeni HSV bezpośrednio możemy wyznaczyć jasność, natomiast korzystająć z Grayscale może być łatwiej wykrywać kontury obiektów na scenie.\n",
        "\n",
        "Oprócz dziedziny intensywności, obraz można również przetwarzać w dziedzinie **częstotliwości**. Obraz w formie macierzy 2D można traktować jako sygnał 2-wymiarowy, a więc podlega on wszelkim operacjom działającym na takich sygnałach, jak **transformata Fouriera**. Reprezentując obraz w dziedzinie częstotliwości mamy możliwość łatwiejszej detekcji krawędzi, obszarów rozmytych i filtrowania obrazów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F268apXm5Ka"
      },
      "source": [
        "Przestrzeń barw RGB:\n",
        "\n",
        "![rgb.png](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/RGB_color_model.svg/256px-RGB_color_model.svg.png)\n",
        "\n",
        "\n",
        "Przestrzeń barw CYMK:\n",
        "\n",
        "\n",
        "![cmyk.png](https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/CYMK_color_model.svg/256px-CYMK_color_model.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-iNZVbHrFpX"
      },
      "source": [
        "## Wczytanie obrazów i początkowa reprezentacja obrazu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKzluR7CQR40"
      },
      "source": [
        "Do najbardziej popularnych bibliotek w **Pythonie** do przetarzania obrazów należą:\n",
        "* OpenCV\n",
        "* Pillow\n",
        "\n",
        "Już na samym początku możemy spotkać pewne różnice w przetwarzaniu obrazów przez te biblioteki. **OpenCV** domyślnie działa na obrazach w formacie **BGR**, natomiast Pillow w formacie **RGB**. **BGR** jest niczym innym jak odwróconą kolejnością kolorów dla każdego piksela (Blue, Green, Red).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "E7yUjnS7xGNR",
        "outputId": "bc0c8509-e903-428a-cccc-b9b255dd5389"
      },
      "outputs": [],
      "source": [
        "# wczytanie obrazu za pomocą biblioteki opencv\n",
        "img = cv2.imread('./lena_std.tif', 1)  # 1 - color (BGR), 0 - grayscale, -1 unchanged (np. do wczytania kanału alpha)\n",
        "img = cv2.resize(img, (256, 256))  # zmiana rozmiaru do 256x256\n",
        "\n",
        "print('Shape:', img.shape)\n",
        "print('BGR:', img[0, 0])\n",
        "print('Obraz wczytany i wyświetlony przez OpenCV\\n')\n",
        "imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "eEhSJD2UO2z5",
        "outputId": "a93bc450-27d6-4fde-dcf3-e12a7fe024d7"
      },
      "outputs": [],
      "source": [
        "# biblioteka opencv domyślnie przetwarza obrazy w formacie BGR\n",
        "# należy o tym pamiętać przy wykorzystywaniu innych bibliotek jak pillow\n",
        "# (obie biblioteki wczytują dane do tablicy numpy, a więc możliwa jest wymiana funkcjonalności pomiędzy bibliotekami)\n",
        "img_pil = np.array(PIL.Image.open('./lena_std.tif'))\n",
        "img_pil = cv2.resize(img_pil, (256, 256))\n",
        "\n",
        "print('Shape:', img_pil.shape)\n",
        "print('RGB:', img_pil[0, 0])\n",
        "print('\\nObraz wczytany przez Pillow i wyświetlony przez OpenCV\\n')\n",
        "imshow(img_pil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "_qLMzv2syxSR",
        "outputId": "022ecc89-7b64-4c4d-b9eb-27f70922785c"
      },
      "outputs": [],
      "source": [
        "# dopiero po transformacji RGB -> BGR obraz zostanie wyświetlony prawidłowo\n",
        "imshow(cv2.cvtColor(img_pil, cv2.COLOR_RGB2BGR))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve-ZDQlIznMr"
      },
      "source": [
        "## Transformacja pomiędzy przestrzeniami barw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTOsMC0tz4OQ"
      },
      "source": [
        "Pomiędzy przestrzeniami barw możemy swobodnie przechodzić podczas przetwarzania obrazu. Co więcej, większość bibliotek ma domyślnie zaimplementowane takie mechanizmy przejścia, pomiędzy najpopularniejszymi przestrzeniami.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj6MOEbX24WR"
      },
      "source": [
        "### RGB - HSV\n",
        "\n",
        "Zakładając dane wejściowe R, G, B, gdzie $R, G, B \\in <0,1>$, transformację z przestrzeni RGB do HSV można przedstawić jako:\n",
        "\n",
        "$C_{max} = max(R,G,B)$  \n",
        "$C_{min} = min(R,G,B)$  \n",
        "$\\Delta = C_{max} - C_{min}$  \n",
        "\n",
        "<br/>\n",
        "\n",
        "${\n",
        "H=\\left\\{\n",
        "  \\begin{array}{ll}\n",
        "    0{\\hspace{0.5cm}\\text{dla}\\hspace{0.5cm}} \\Delta = 0\\\\\n",
        "    60 * (\\frac{G - B}{\\Delta} \\mod 6){\\hspace{0.5cm}\\text{dla}\\hspace{0.5cm}} C_{max} = R\\\\\n",
        "    60 * (\\frac{B - R}{\\Delta} + 2){\\hspace{0.5cm}\\text{dla}\\hspace{0.5cm}} C_{max} = G\\\\\n",
        "    60 * (\\frac{R - G}{\\Delta} + 4){\\hspace{0.5cm}\\text{dla}\\hspace{0.5cm}} C_{max} = B\n",
        "  \\end{array}\n",
        "\\right.}$  \n",
        "<br/>\n",
        "${\n",
        "S=\\left\\{\n",
        "  \\begin{array}{ll}\n",
        "    0{\\hspace{0.5cm}\\text{dla}\\hspace{0.5cm}} C_{max} = 0\\\\\n",
        "    \\frac{\\Delta}{C_{max}} {\\hspace{0.5cm}\\text{dla}\\hspace{0.5cm}} C_{max} \\neq 0\n",
        "  \\end{array}\n",
        "\\right.}$  \n",
        "<br/>\n",
        "$V = C_{max}$\n",
        "<br/>\n",
        "\n",
        "Uwaga #1: S i V powinny być przeskalowane do wartości z przedziału $<0, 255>$\n",
        "\n",
        "Uwaga #2: OpenCV przetrzymuje wartość H w zakresie $<0, 180>$, a więc ostatecznie H powinno być podzielone przez 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd0Ozsbl7R4Y"
      },
      "source": [
        "### RGB - Grayscale\n",
        "\n",
        "Transformację z przestrzeni RGB do Grayscale można przedstawić jako:\n",
        "\n",
        "$$Gray = 0.2989 * R + 0.5870 * G + 0.1140 * B$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pInxvPn08b2X"
      },
      "source": [
        "### Implementacja w OpenCV\n",
        "\n",
        "OpenCV zawiera gotową funkcję **cvtColor**, która jako pierwszy parametr pobiera obraz do przetworzenia, a jako drugi stałą, określającą typ transformacji (stałe oznaczone przez zmienne np. COLOR_RGB2BGR)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "9PSKmkRmrq5V",
        "outputId": "a067f224-7f99-4dc3-ccbb-e585c2aa888c"
      },
      "outputs": [],
      "source": [
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "img_luv = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
        "img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "imshow(np.concatenate([img_rgb, img_hsv, img_luv], 1))\n",
        "imshow(img_grayscale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44wMBDkUK6JU",
        "outputId": "8d6fd94e-0a0e-4a57-f2b7-1b6237e8e4b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "img_grayscale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzEL41dH1LlU"
      },
      "source": [
        "### **Zadanie 1**\n",
        "\n",
        "Zaimplementuj następujące transformacje:\n",
        "* BGR do RGB,\n",
        "* BGR do HSV,\n",
        "* BGR do Grayscale\n",
        "\n",
        "Wyniki zostaną porównane z wynikami funkcji zawartych w OpenCV.\n",
        "\n",
        "**Uwaga:**  \n",
        "Mogą występować różnice implementacyjne pomiędzy tymi samymi transformacjami, które mogą wynikać z błędów numerycznych lub po prostu innego typu zaogrąglania / ucinania wartości, przy transformacji liczby zmiennoprzecinkowej do całkowitoliczbowej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "-88_z93B0RA-",
        "outputId": "0dd72175-ab7e-4498-8089-b329fd5bf9b4"
      },
      "outputs": [],
      "source": [
        "def BGR2RGB(img_bgr):\n",
        "    return img_bgr[:,:,::-1]\n",
        "\n",
        "\n",
        "def BGR2HSV(img_bgr):\n",
        "    img_bgr_norm = img_bgr / 255\n",
        "    shape = img_bgr.shape\n",
        "    C_max = np.max(img_bgr_norm, axis=2)\n",
        "    C_min = np.min(img_bgr_norm, axis=2)\n",
        "    delta = C_max - C_min\n",
        "\n",
        "    H = np.zeros((shape[0], shape[1]))\n",
        "    for i in range(shape[0]):\n",
        "        for j in range(shape[1]):\n",
        "            r, g, b = (img_bgr_norm[i][j][2], img_bgr_norm[i][j][1], img_bgr_norm[i][j][0])\n",
        "            C_m = C_max[i][j]\n",
        "            d = delta[i][j]\n",
        "            if d == 0:\n",
        "                H[i][j] = 0\n",
        "            elif C_m == r:\n",
        "                H[i][j] = 60 * (((g-b)/d) % 6)\n",
        "            elif C_m == g:\n",
        "                H[i][j] = 60 * (((b-r)/d) + 2)\n",
        "            elif C_m == b:\n",
        "                H[i][j] = 60 * (((r-g)/d) + 4)\n",
        "            H[i][j] = round(H[i][j])\n",
        "    H = H / 2\n",
        "\n",
        "    \n",
        "    S = np.zeros((shape[0], shape[1]))\n",
        "    V = np.zeros((shape[0], shape[1]))\n",
        "    for i in range(shape[0]):\n",
        "        for j in range(shape[1]):\n",
        "            if C_max[i][j] == 0:\n",
        "                S[i][j] = 0\n",
        "            else:\n",
        "                S[i][j] = round((delta[i][j] / C_max[i][j]) * 255)\n",
        "            V[i][j] = round(C_max[i][j] * 255)\n",
        "    \n",
        "    return np.stack((H, S, V), axis=2)\n",
        "\n",
        "\n",
        "def BGR2Gray(img_bgr):\n",
        "    shape = img_bgr.shape\n",
        "    img_gray = np.zeros((shape[0], shape[1]))\n",
        "    for i in range(shape[0]):\n",
        "        for j in range(shape[1]):\n",
        "            # 0.2989 * R + 0.5870 * G + 0.1140 * B\n",
        "            img_gray[i][j] = img_bgr[i][j][0] * 0.1140 + img_bgr[i][j][1] * 0.5870 + img_bgr[i][j][2] * 0.2989\n",
        "    return img_gray\n",
        "\n",
        "\n",
        "img_rgb_2 = BGR2RGB(img)\n",
        "img_hsv_2 = BGR2HSV(img)\n",
        "img_grayscale_2 = BGR2Gray(img)\n",
        "\n",
        "imshow(np.concatenate([img_rgb_2, img_hsv_2], 1))\n",
        "imshow(img_grayscale_2)\n",
        "\n",
        "print('\\n===\\n')\n",
        "print('BGR2RGB Check:', (img_rgb == img_rgb_2).all())\n",
        "print('BGR2HSV Check:', np.allclose(img_hsv, img_hsv_2, 1, 0))\n",
        "print('BGR2Grayscale Check:', np.allclose(img_grayscale, img_grayscale_2, 1, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1lNoM1fKbOt",
        "outputId": "3cec8052-11fb-488d-abdd-ce27f2ebf69f"
      },
      "outputs": [],
      "source": [
        "img_grayscale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXLk2fEn2Nkz"
      },
      "source": [
        "## Własne przestrzenie barw\n",
        "\n",
        "Przestrzenie barw takie jak RGB czy HSV są standardowymi przestrzeniami, wynikającymi z samej natury światła. Nie ogranicza to jednak przed tworzeniem własnych przestrzeni barw. Poniżej zostały przedstawione metody **pseudokolorowania** - czyli nadania pikselom koloru na podstawie sztucznie przygotowanej przestrzeni barw.\n",
        "\n",
        "Szczególnie interesującą przestrzenią może wydawać się przestrzeń **Hot**, która dla pikseli o większej intensywności (grayscale) nadaje cieplejszą barwę (kolor żółty).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "OJrlFr7e0eoC",
        "outputId": "3e69c3f2-e307-4e7b-8252-77f2ea3880b3"
      },
      "outputs": [],
      "source": [
        "img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_hot = cv2.applyColorMap(img_grayscale, cv2.COLORMAP_HOT)\n",
        "img_bone = cv2.applyColorMap(img_grayscale, cv2.COLORMAP_BONE)\n",
        "img_ocean = cv2.applyColorMap(img_grayscale, cv2.COLORMAP_OCEAN)\n",
        "\n",
        "imshow(np.concatenate([img, img_hot, img_bone, img_ocean], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CSmV3B1_E7T"
      },
      "source": [
        "Aby zaaplikować swoją własną przestrzeń barw, możemy skorzystać z funkcji w bibliotece OpenCV **LUT** (Lookup Table). W poniższym przykładzie przygotowano 3 przestrzenie barw (lut_1, lut_2, lut_3). Każda z tych tablic jest funkcją mapowania pomiędzy każdą z 256 wartości (uint8) a nową wartością. Funkcję można również zastosować dla obrazów **wielokanałowych**.\n",
        "\n",
        "* **Lut_1** jest funkcją tożsamościową, dla każdej intensywności piksela zwacana jest ta sama intensywność,\n",
        "* **Lut_2** dla pierwszych 100 wartości (0-99) zwraca intensywność 255, dla kolejnych 100 (100-199) intensywność 0 i dla przedziału 200-256 intensywność 255. Jest to nic innego niż złożenie progowania obrazu,\n",
        "* **Lut_3** - tworzy ''kubełki'' po 64 wartości (a więc 256 / 64 = 4 progi)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "ZVXRCb3d_Cmc",
        "outputId": "4e4ed717-32af-42b1-dd11-e8ab2945520d"
      },
      "outputs": [],
      "source": [
        "lut_1 = np.array(range(256))\n",
        "lut_2 = np.array([255] * 100 + [0] * 100 + [255]* 56)\n",
        "lut_3 = 64 * (np.array(range(256)) // 64)\n",
        "\n",
        "img_lut_1 = cv2.LUT(img_grayscale, lut_1)\n",
        "img_lut_2 = cv2.LUT(img_grayscale, lut_2)\n",
        "img_lut_3 = cv2.LUT(img_grayscale, lut_3)\n",
        "\n",
        "imshow(np.concatenate([img_grayscale, img_lut_1, img_lut_2, img_lut_3], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSaWikZEAp_J"
      },
      "source": [
        "### Zadanie 2\n",
        "\n",
        "Dla obrazu Lenna w przestrzeni Grayscale najpierw przekształć go do przestrzeni zawierającej 8 progów (kubełków), a następnie transformuj obraz do przestrzeni **Hot**.\n",
        "\n",
        "Wyświetl wyniki pośrednie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lut_8_colors = 32 * (np.array(range(256)) // 32)\n",
        "\n",
        "img_lut = cv2.LUT(img_grayscale, lut_8_colors).astype(np.uint8)\n",
        "imshow(np.concatenate([img_grayscale, img_lut], 1))\n",
        "\n",
        "img_hot = cv2.applyColorMap(img_lut, cv2.COLORMAP_HOT)\n",
        "imshow(img_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUhcyMWqs7F"
      },
      "source": [
        "# Operacje jednopunktowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJoh1cHIrGFy"
      },
      "source": [
        "Operacją jednopunktową nazywamy taką transformację przekształcającą obraz w inny obraz, dla której wynik poszczególnego piksela zależy od odpowiadającemu mu pikselowi w obrazie wejściowym. Formalnie dowolną operację obrazową możemy zapisać następująco:\n",
        "\n",
        "$$F : I_{in} \\rightarrow I_{out}$$\n",
        "\n",
        "gdzie:\n",
        "\n",
        "* F - funkcja przekształcająca,\n",
        "* $I_{in}$ - dziedzina obrazu wejściowego,\n",
        "* $I_{out}$ - dziedzdina obrazu wyjściowego\n",
        "\n",
        "dodatkowo, przy ograniczeniu:\n",
        "\n",
        "$$I_{out}(x,y) = F(I_{in}(x,y)$$\n",
        "\n",
        "oznaczającym, że piksel obrazu wyjściowego jest wynikiem działania funkcji F na odpowiadającym mu pikselu obrazu wejściowego, możemy zdefiniować operację jednopunktową.\n",
        "\n",
        "Przykładowymi operacjami jednopunktowymi są (dla uproszczenia zakładamy, że $i \\in <0, 1>$):\n",
        "\n",
        "* tożsamość: $$F(i) = i$$\n",
        "* odwrotność: $$F(i) = 1 - i$$\n",
        "* korekcja gamma: $$F(i, \\gamma) = i^\\gamma$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLJzdat9Cjc7"
      },
      "source": [
        "### Funkcje pomocnicze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNCkcr4pCfIL"
      },
      "outputs": [],
      "source": [
        "def plot_simple(ax):\n",
        "    ax.set_title('Podstawowe transformacje')\n",
        "    ax.set_xlabel('Intensywność wejściowa')\n",
        "    ax.set_ylabel('Intensywność wyjściowa')\n",
        "    ax.plot(i, identity(i), label='identity')\n",
        "    ax.plot(i, invert(i), label='invert')\n",
        "    ax.grid()\n",
        "    ax.legend()\n",
        "\n",
        "def plot_gamma(ax):\n",
        "    ax.set_title('Korekcja gamma dla różnych parametrów')\n",
        "    ax.set_xlabel('Intensywność wejściowa')\n",
        "    ax.set_ylabel('Intensywność wyjściowa')\n",
        "    ax.plot(i, gamma(i, 0.1), label='0.1')\n",
        "    ax.plot(i, gamma(i, 0.2), label='0.2')\n",
        "    ax.plot(i, gamma(i, 0.5), label='0.5')\n",
        "    ax.plot(i, gamma(i, 1.0), label='1.0')\n",
        "    ax.plot(i, gamma(i, 1.8), label='1.8')\n",
        "    ax.plot(i, gamma(i, 3.0), label='4.0')\n",
        "    ax.plot(i, gamma(i, 4.5), label='4.5')\n",
        "    ax.grid()\n",
        "    ax.legend()\n",
        "\n",
        "def plot_l_threshold(ax):\n",
        "    ax.set_title('Dolne odcięcie dla kolejnych progów')\n",
        "    ax.set_xlabel('Intensywność wejściowa')\n",
        "    ax.set_ylabel('Intensywność wyjściowa')\n",
        "    ax.plot(i, l_threshold(i, 0.1), label='0.1')\n",
        "    ax.plot(i, l_threshold(i, 0.5), label='0.5')\n",
        "    ax.plot(i, l_threshold(i, 0.9), label='0.9')\n",
        "    ax.grid()\n",
        "    ax.legend()\n",
        "\n",
        "\n",
        "def plot_u_threshold(ax):\n",
        "    ax.set_title('Górne odcięcie dla kolejnych progów')\n",
        "    ax.set_xlabel('Intensywność wejściowa')\n",
        "    ax.set_ylabel('Intensywność wyjściowa')\n",
        "    ax.plot(i, u_threshold(i, 0.1), label='0.1')\n",
        "    ax.plot(i, u_threshold(i, 0.5), label='0.5')\n",
        "    ax.plot(i, u_threshold(i, 0.9), label='0.9')\n",
        "    ax.grid()\n",
        "    ax.legend()\n",
        "\n",
        "\n",
        "def plot_quad(ax):\n",
        "    ax.set_title('Funkcja kwadratowa')\n",
        "    ax.set_xlabel('Intensywność wejściowa')\n",
        "    ax.set_ylabel('Intensywność wyjściowa')\n",
        "    ax.plot(i, quad(i, 4.0), label='4.0')\n",
        "    ax.plot(i, quad(i, 2.0), label='2.0')\n",
        "    ax.plot(i, quad(i, 1.0), label='1.0')\n",
        "    ax.grid()\n",
        "    ax.legend()\n",
        "\n",
        "\n",
        "def plot_stacked(ax):\n",
        "    ax.set_title('Złożenie transformacji')\n",
        "    ax.set_xlabel('Intensywność wejściowa')\n",
        "    ax.set_ylabel('Intensywność wyjściowa')\n",
        "    ax.plot(i, u_threshold(gamma(invert(i), 0.3), 0.7), label='threshold(gamma(invert))')\n",
        "    ax.plot(i, quad(l_threshold(i, 0.4), 3.0), label='quad(threshold)')\n",
        "    ax.grid()\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R8Mmw26Coav"
      },
      "source": [
        "### Transformacje punktowe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB37bl_okfO6"
      },
      "source": [
        "Poniżej, znajdują się implementacje operacji **tożsamości, odwrotności i korekcji gamma** oraz ich wizualizacje."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "e459cNcTrmnh",
        "outputId": "acb877e7-3aa9-4609-bdcd-1a80bf5bffa0"
      },
      "outputs": [],
      "source": [
        "def identity(i):\n",
        "    return i\n",
        "\n",
        "\n",
        "def invert(i):\n",
        "    return 1.0 - i\n",
        "\n",
        "\n",
        "def gamma(i, g):\n",
        "    return i ** g\n",
        "\n",
        "i = np.arange(0.0, 1.0, 0.01)  # dziedzina obrazu\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,5), sharex='all', sharey='all')\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([0.0, 1.0])\n",
        "axes.set_ylim([0.0, 1.0])\n",
        "plot_simple(ax[0])\n",
        "plot_gamma(ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOxbktYWCztO"
      },
      "source": [
        "### Zadanie 3\n",
        "\n",
        "Zdefiniuj następujące transformacje:\n",
        "\n",
        "* Dolne odcięcie (**l_threshold**) - wartości intensywności wejściowej **poniżej** pewnego progu powinny być sprowadzone do tego właśnie progu,\n",
        "* Górne odcięcie (**u_threshold**) - wartości intensywności wejściowej **powyżej** pewnego progu powinny być sprowadzone do tego właśnie progu,\n",
        "* Funkcja kwadratowa (**quad**) - funkcja powinna mieć miejsca zerowe dla intensywności wejściowych 0.0 i 1.0 (parametr **a** powinien jedynie sterować **maksimum** funkcji)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# todo:\n",
        "def l_threshold(i, threshold):\n",
        "    return np.clip(i, a_min=threshold, a_max=None)\n",
        "\n",
        "\n",
        "# todo:\n",
        "def u_threshold(i, threshold):\n",
        "    return np.clip(i, a_min=None, a_max=threshold)\n",
        "\n",
        "\n",
        "# todo:\n",
        "def quad(i, a):\n",
        "    return -a * i**2 + a * i\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(15,15), sharex='all', sharey='all')\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([0.0, 1.0])\n",
        "axes.set_ylim([0.0, 1.0])\n",
        "plot_l_threshold(ax[0, 0])\n",
        "plot_u_threshold(ax[0, 1])\n",
        "plot_quad(ax[1, 0])\n",
        "plot_stacked(ax[1, 1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_2rnO1YzNSf"
      },
      "source": [
        "### Funkcje pomocnicze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elKFklKOFBiK"
      },
      "outputs": [],
      "source": [
        "def imshow_simple(img_bgr):\n",
        "    print('\\n===')\n",
        "    print('Tożsamość | Odwrotność\\n')\n",
        "    img_bgr = img_bgr / 255.0\n",
        "    imshow(np.concatenate([\n",
        "      identity(img_bgr),\n",
        "      invert(img_bgr)\n",
        "    ], 1) * 255.0)\n",
        "\n",
        "def imshow_gamma(img_bgr):\n",
        "    print('\\n===')\n",
        "    print('Korekcja Gamma 0.1 | 0.5 | 2.0 | 4.0\\n')\n",
        "    img_bgr = img_bgr / 255.0\n",
        "    imshow(np.concatenate([\n",
        "      gamma(img_bgr, 0.1),\n",
        "      gamma(img_bgr, 0.5),\n",
        "      gamma(img_bgr, 2.0),\n",
        "      gamma(img_bgr, 4.0)\n",
        "    ], 1) * 255.0)\n",
        "\n",
        "def imshow_l_threshold(img_bgr):\n",
        "    print('\\n===')\n",
        "    print('Dolne odcięcie 0.3 | 0.5 | 0.9\\n')\n",
        "    img_bgr = img_bgr / 255.0\n",
        "    imshow(np.concatenate([\n",
        "      l_threshold(img_bgr, 0.3),\n",
        "      l_threshold(img_bgr, 0.5),\n",
        "      l_threshold(img_bgr, 0.9)\n",
        "    ], 1) * 255.0)\n",
        "\n",
        "\n",
        "def imshow_u_threshold(img_bgr):\n",
        "    print('\\n===')\n",
        "    print('Górne odcięcie 0.3 | 0.5 | 0.9\\n')\n",
        "    img_bgr = img_bgr / 255.0\n",
        "    imshow(np.concatenate([\n",
        "      u_threshold(img_bgr, 0.3),\n",
        "      u_threshold(img_bgr, 0.5),\n",
        "      u_threshold(img_bgr, 0.9)\n",
        "    ], 1) * 255.0)\n",
        "\n",
        "\n",
        "def imshow_quad(img_bgr):\n",
        "    print('\\n===')\n",
        "    print('Funkcja kwadratowa 4.0 | 2.0 | 1.0\\n')\n",
        "    img_bgr = img_bgr / 255.0\n",
        "    imshow(np.concatenate([\n",
        "      quad(img_bgr, 4.0),\n",
        "      quad(img_bgr, 2.0),\n",
        "      quad(img_bgr, 1.0)\n",
        "    ], 1) * 255.0)\n",
        "\n",
        "\n",
        "def imshow_stacked(img_bgr):\n",
        "    print('\\n===')\n",
        "    print('Złożenie operacji u_thrershold(gamma(invert))) | quad(l_threshold())\\n')\n",
        "    img_bgr = img_bgr / 255.0\n",
        "    imshow(np.concatenate([\n",
        "      u_threshold(gamma(invert(img_bgr), 0.3), 0.7),\n",
        "      quad(l_threshold(img_bgr, 0.4), 3.0)\n",
        "    ], 1) * 255.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mclZN_QtzQwO"
      },
      "source": [
        "### Aplikacja operacji jednopunktowych do obrazów\n",
        "\n",
        "Powyżej pokazane zostały charakterystyki funkcji realizujących podstawowe operacje na obrazach. Operacje te można bezpośrednio użyć do obrazów, otrzymując nowy, transformowany obraz.\n",
        "\n",
        "Poniżej zaprezentowane zostały te same funkcje, co powyżej, zastosowane do obrazu Lenna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g5rWRTA3Gs0y",
        "outputId": "d073bdbd-53a8-4b1e-bc32-ba0fa39fd377"
      },
      "outputs": [],
      "source": [
        "imshow_simple(img)\n",
        "imshow_gamma(img)\n",
        "imshow_l_threshold(img)\n",
        "imshow_u_threshold(img)\n",
        "imshow_quad(img)\n",
        "imshow_stacked(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ6AF_RuqtHu"
      },
      "source": [
        "# Arytmetyka obrazowa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HKRK158rGaN"
      },
      "source": [
        "Wartości intensywności / częstotliwości pikseli obrazów reprezentowane są jako liczby (czy to całkowitoliczbowe czy zmiennoprzecinkowe). Implikuje to możliwość wykonania pewnych operacji na parach (zestawach) obrazów, jak dodawanie, odejmowanie, uśrednianie, itp.\n",
        "\n",
        "Poniżej zostało przedstawione naiwne rozwiązanie problemu scalania obrazów reprezentujących ten sam obiekt, z ustawioną różną ostrością."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKibV05L0Z4D"
      },
      "outputs": [],
      "source": [
        "files = [\n",
        "    './bug/b_bigbug0000_croppped.png',\n",
        "    './bug/b_bigbug0001_croppped.png',\n",
        "    './bug/b_bigbug0002_croppped.png',\n",
        "    './bug/b_bigbug0003_croppped.png',\n",
        "    './bug/b_bigbug0004_croppped.png',\n",
        "    './bug/b_bigbug0005_croppped.png',\n",
        "    './bug/b_bigbug0006_croppped.png',\n",
        "    './bug/b_bigbug0007_croppped.png',\n",
        "    './bug/b_bigbug0008_croppped.png',\n",
        "    './bug/b_bigbug0009_croppped.png',\n",
        "    './bug/b_bigbug0010_croppped.png',\n",
        "    './bug/b_bigbug0011_croppped.png',\n",
        "    './bug/b_bigbug0012_croppped.png',\n",
        "]\n",
        "\n",
        "# wczytanie danych\n",
        "bugs = [cv2.imread(f, 1) for f in files]\n",
        "bugs = list(map(lambda i: cv2.resize(i, None, fx=0.3, fy=0.3), bugs))\n",
        "\n",
        "# wczytanie spodziewanego wyniku algorytmu\n",
        "result = cv2.imread('./bug/result.png', 1)\n",
        "result = cv2.resize(result, None, fx=0.3, fy=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXpCVBwF2JYF"
      },
      "source": [
        "Na wczytanych obrazach możemy wykonać operację uśredniania. Spodziewanym rezultatem jest obraz, z średnio dobrą ostrością.\n",
        "\n",
        "Gdyby wyszczególnić obszary, w których ostrość obrazu jest wysoka, możliwe byłoby złożenie obrazu ostrego w każdym miejscu (do tego potrzebne są operacje splotowe, które zostaną wprowadzone na kolejnych zajęciach)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XUnNAlX_riXk",
        "outputId": "02da181d-9671-483e-c20e-be1f63a718fe"
      },
      "outputs": [],
      "source": [
        "#\n",
        "bug = np.stack(bugs, 0).mean(0)\n",
        "\n",
        "print('\\n===')\n",
        "print('Zdjęcia mrówki z ostrością na rożnej odległości\\n')\n",
        "imshow(np.concatenate(bugs[0:4], 1))\n",
        "imshow(np.concatenate(bugs[4:8], 1))\n",
        "imshow(np.concatenate(bugs[8:12], 1))\n",
        "print('\\n===')\n",
        "print('Zwykłe uśrednienie obrazów składowych oraz docelowy obraz\\n')\n",
        "imshow(np.concatenate([bug, result], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWM7vqmcl07M"
      },
      "source": [
        "### Zadanie 4\n",
        "\n",
        "Zadanie dotyczy przećwiczenia operacji arytmetycznych na obrazach oraz prostej detekcji cech opartej na przetwarzaniu jednopunktowym.\n",
        "\n",
        "Korzystając z obrazu lenna znajdź obszary na obrazie, dla których wartości grayscale są z przedziału 120-160.\n",
        "\n",
        "Następnie zaproponuj operacje, które dla wybranych obszarów zwrócą odwrotność obrazu Lenna (RGB), a dla pozostałych obszarów przekopiują piksele z obrazu Lenna (RGB).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_find_val = np.zeros_like(img)\n",
        "shape = img.shape\n",
        "for i in range(shape[0]):\n",
        "    for j in range(shape[1]):\n",
        "        gray_val = img[i][j][0] * 0.1140 + img[i][j][1] * 0.5870 + img[i][j][2] * 0.2989\n",
        "        if gray_val >= 120 and gray_val <= 160:\n",
        "            img_find_val[i][j] = np.full(3, 255) - img[i][j]\n",
        "        else:\n",
        "            img_find_val[i][j] = img[i][j]\n",
        "\n",
        "imshow(img_find_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3G3wpLqqtQN"
      },
      "source": [
        "# Operacje geometryczne\n",
        "\n",
        "Oprócz operacji modyfikujących pojedynczy piksel istnieją również takie, które przekształcają geometrię całego obrazu. Do podstawowych przekształceń geometrycznych zaliczamy:\n",
        "\n",
        "* przesunięcie (horyzontalne i wertykalne),\n",
        "* obrót,\n",
        "* skalowanie,\n",
        "* pochylenie\n",
        "\n",
        "Powyższe operacje nazywamy **operacjami affinicznymi** i możemy je reprezentować jako:\n",
        "\n",
        "$$\n",
        "T = \\begin{bmatrix}\n",
        "a_{11} & a_{12} & a_{13}\\\\\n",
        "a_{21} & a_{22} & a_{23}\\\\\n",
        "a_{31} & a_{32} & a_{33}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Wówczas, podstawowe operacje możemy zdefiniować jako:\n",
        "* tożsamość:\n",
        "$$\n",
        "T = \\begin{bmatrix}\n",
        "1 & 0 & 0\\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "* przesunięcie (horyzontalne i wertykalne),\n",
        "$$\n",
        "T = \\begin{bmatrix}\n",
        "1 & 0 & t_x\\\\\n",
        "0 & 1 & t_y\\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "* obrót,\n",
        "$$\n",
        "T = \\begin{bmatrix}\n",
        "\\cos(\\alpha) & -\\sin(\\alpha) & 0\\\\\n",
        "\\sin(\\alpha) & \\cos(\\alpha) & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "* skalowanie,\n",
        "$$\n",
        "T = \\begin{bmatrix}\n",
        "c_x & 0 & 0\\\\\n",
        "0 & c_y & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "* pochylenie\n",
        "$$\n",
        "T = \\begin{bmatrix}\n",
        "1 & c_x & 0\\\\\n",
        "c_y & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Powyższe operacje można składać za pomocą mnożenia macierzy.\n",
        "\n",
        "**Uwaga:**  \n",
        "OpenCV zawiera operację aplikacji operacji afinicznych, jednak przyjmuje ona przekształcenie w formie:\n",
        "\n",
        "$$\n",
        "T = \\begin{bmatrix}\n",
        "a_{11} & a_{12} & a_{13}\\\\\n",
        "a_{21} & a_{22} & a_{23}\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "fRgm_VasrfRy",
        "outputId": "23052e93-6b8a-4318-8500-4ab505ca4b4c"
      },
      "outputs": [],
      "source": [
        "# przesunięcie\n",
        "t1 = np.array([\n",
        "  [1, 0, 50],\n",
        "  [0, 1, -50],\n",
        "  [0, 0, 1]\n",
        "], np.float32)\n",
        "\n",
        "# obrót\n",
        "t2 = np.array([\n",
        "  [0.0, -1.0, 256],\n",
        "  [1.0, 0.0, 0],\n",
        "  [0, 0, 1]\n",
        "], np.float32)\n",
        "\n",
        "# skala\n",
        "t3 = np.array([\n",
        "  [0.5, 0, 0],\n",
        "  [0, 0.5, 0],\n",
        "  [0, 0, 1]\n",
        "], np.float32)\n",
        "\n",
        "img_t1 = cv2.warpAffine(img, t1[:2], img.shape[:2])\n",
        "img_t2 = cv2.warpAffine(img_t1, t2[:2], img_t1.shape[:2])\n",
        "img_t3 = cv2.warpAffine(img_t2, t3[:2], img_t2.shape[:2])\n",
        "\n",
        "imshow(np.concatenate([img, img_t1, img_t2, img_t3], 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDZ_du7e8Tf2"
      },
      "source": [
        "Na powyższym przykładzie widać, że poszczególne wyniki operacji afinicznych są **stratne**. Można zauważyć, że po pierwszej operacji przesunięcia część kolorowego obrazu znajduje się poza kadrem i zostaje utracona. Skutkuje to błędnym późniejszym przetwarzaniem (mimo poprawnej składni matematycznej).\n",
        "\n",
        "Rozwiązaniem jest złożenie operacji afinicznych korzystając z operacji mnożenia macierzy. Poniżej znajduje się pojedyncze przekształcenie zawierające wszystkie powyższe operacje, jednocześnie nie tracąc informacji pomiędzy operacjami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "l3RhmhPE8UND",
        "outputId": "e89503a8-4544-4f98-b5a4-4a9d59598ac0"
      },
      "outputs": [],
      "source": [
        "T = t3 @ t2 @ t1\n",
        "\n",
        "img_direct = cv2.warpAffine(img, T[:2], img.shape[:2])\n",
        "imshow(img_direct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDNHoYlZzZpF"
      },
      "source": [
        "# Histogram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGt-RmqtGBhx"
      },
      "source": [
        "Wyliczenie histogramu polega na zliczeniu liczebności pikseli o danej wartości. Innymi słowy, histogram pokazuje, jak dużo pikseli o pewnej intensywności znajduje się na obrazie.\n",
        "\n",
        "Aby wyliczyć histogram dla obrazu, możemy skorzystać z gotowej funkcji zawartej w bibliotece matplotlib **hist()**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "JrK4XNGDpEkV",
        "outputId": "36410e3f-d45e-4c46-92c0-e8a92847b7f4"
      },
      "outputs": [],
      "source": [
        "h, _, _ = plt.hist(img_grayscale.flatten(), 256, histtype='step')\n",
        "plt.show()\n",
        "imshow(img_grayscale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s6FQSn7GetX"
      },
      "source": [
        "Dzieki histogramowi obrazu można zauważyć pewne nieregularności w liczbie występowania intensywności pikseli. W przypadku gdy histogram jest **niezrównoważony**, a więc pewne przedziały intensywności dominują na obrazie, możemy zastosować metodę wyrównywania histogramu, aby przekształcony obraz posiadał bardziej wyrównaną liczbę wszystkich intensywności.\n",
        "\n",
        "Dzięki takiej operacji możemy obrazy bardzo ciemne, na których na pierwszy rzut oka nie widać żadnych punktów charakterystycznych, przekształcić w taki sposób, aby zmiany intensywności pikseli wyszczególniły wcześniej niewidoczne zmiany na obrazie.\n",
        "\n",
        "**Wyrównywanie histogramu** zaimplementowane jest w bibliotece OpenCV jako **equalizeHist**, która pobiera obraz na wejściu i zwraca obraz po transformacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "lfDSxfqKpLe6",
        "outputId": "124a0bbf-5ef9-433d-feb9-0dd6bca05732"
      },
      "outputs": [],
      "source": [
        "img_equalized = cv2.equalizeHist(img_grayscale)\n",
        "plt.hist(img_equalized.flatten(), 255, histtype='step')\n",
        "plt.show()\n",
        "imshow(img_equalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzJf3jZZHr59"
      },
      "source": [
        "Aby ręcznie przeprowadzić wyrównywanie histogramu najpierw należy policzyć **dystrybuantę** intensywności pikseli. Dystrybuanta mówi nam, jakie jest prawdopodobieństwo, że wybierając dowolny piksel z obrazu, jego intensywność będzie mniejsza od danej intensywności na dystrybuancie.\n",
        "\n",
        "Następnym krokiem jest normalizacja otrzymanej dystrybuanty (aby wartości przeciwdziedziny były z zakresu <0, 255>). W ten sposób otrzymaliśmy, wprowadzoną wcześniej na zajęciach, własną przestrzeń barw (lookup table).\n",
        "\n",
        "Posiadając tę tablicę, standardowo możemy skorzystać z operacji **LUT()**, aby otrzymać obraz po wyrównaniu histogramu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "x1p--AJdqBdl",
        "outputId": "04ef371d-a613-46a0-b061-0cec88777faa"
      },
      "outputs": [],
      "source": [
        "cdf_h = np.cumsum(h)\n",
        "plt.plot(cdf_h)\n",
        "cdf_lut = (255 * cdf_h / np.max(cdf_h)).astype(np.uint8)\n",
        "print(cdf_lut)\n",
        "imshow(cv2.LUT(img_grayscale, cdf_lut))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "H_2rnO1YzNSf"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
