{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systemy uczące się - Zad. dom. 1: Minimalizacja ryzyka empirycznego\n",
    "\n",
    "### Autor rozwiązania: Maciej Wieczorek, 148141\n",
    "\n",
    "Celem zadania jest zaimplementowanie własnego drzewa decyzyjnego wykorzystującego idee minimalizacji ryzyka empirycznego. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twoja implementacja\n",
    "\n",
    "Twoim celem jest uzupełnić poniższą klasę `TreeNode` tak by po wywołaniu `TreeNode.fit` tworzone było drzewo decyzyjne minimalizujące ryzyko empiryczne. Drzewo powinno wspierać problem klasyfikacji wieloklasowej (jak w przykładzie poniżej). Zaimplementowany algorytm nie musi (ale może) być analogiczny do zaprezentowanego na zajęciach algorytmu dla klasyfikacji. Wszelkie przejawy inwencji twórczej wskazane. Pozostaw komenatrze w kodzie, które wyjaśniają Twoje rozwiązanie.\n",
    "\n",
    "Schemat oceniania:\n",
    "- wynik na ukrytym zbiorze testowym (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u 1 +20%,\n",
    "- wynik na ukrytym zbiorze testowym (automatyczna ewaluacja) celność klasyfikacji >= prostego baseline'u 2 +40%,\n",
    "- wynik na ukrytym zbiorze testowym (automatyczna ewaluacja) celność klasyfikacji >= bardziej zaawansowanego baseline'u 3 +40%.\n",
    "\n",
    "Niedozwolone jest korzystanie z zewnętrznych bibliotek do tworzenia drzewa decyzyjnego (np. scikit-learn). \n",
    "Możesz jedynie korzystać z biblioteki numpy.\n",
    "\n",
    "#### Uwaga: Możesz dowolnie modyfikować elementy tego notebooka (wstawiać komórki i zmieniać kod), o ile będzie się w nim na koniec znajdowała kompletna implementacja klasy `TreeNode` w jednej komórce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(X):\n",
    "\t_, value_counts = np.unique(X, return_counts=True)\n",
    "\tproba = value_counts / len(X)\n",
    "\n",
    "\treturn -np.sum(proba * np.log2(proba))\n",
    "\n",
    "def measure_split_value(target, index):\n",
    "\ttarget_l = target[:index+1]\n",
    "\ttarget_r = target[index+1:]\n",
    "\tentropy_l = entropy(target_l) * (len(target_l) / len(target))\n",
    "\tentropy_r = entropy(target_r) * (len(target_r) / len(target))\n",
    "\tinfo_gain = entropy(target) - (entropy_l + entropy_r)\n",
    "\treturn info_gain \n",
    "\n",
    "def split_data(data, target, split):\n",
    "\tl_indices = np.where(data[:, split[0]] <= split[1])[0]\n",
    "\tr_indices = np.where(data[:, split[0]] > split[1])[0]\n",
    "\treturn (data[l_indices], target[l_indices], data[r_indices], target[r_indices])\n",
    "\n",
    "\n",
    "class TreeNode(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.left = None # Typ: Node, wierzchołek znajdujący się po lewej stornie\n",
    "\t\tself.right = None # Typ: Node, wierzchołek znajdujący się po prawej stornie\n",
    "\t\tself.value = None # klasa decyzyjna liścia\n",
    "\t\tself.best_split = None # warunek podziału, para: (indeks atrybutu, wartość na atrybucie)\n",
    "\t\t\n",
    "\tdef fit(self, data, target):\n",
    "\t\t\"\"\"\n",
    "\t\tArgumenty:\n",
    "\t\tdata -- numpy.ndarray, macierz cech o wymiarach (n, m), gdzie n to liczba przykładów, a m to liczba cech\n",
    "\t\ttarget -- numpy.ndarray, wektor klas o długości n, gdzie n to liczba przykładów\n",
    "\t\t\"\"\"\n",
    "\t\tbest_split_gain = 0\n",
    "\t\tfor i in range(data.shape[1]):\n",
    "\t\t\tattr_data = data[:,i]\n",
    "\t\t\tsorted_indices = np.argsort(attr_data)\n",
    "\t\t\tsorted_attr = attr_data[sorted_indices]\n",
    "\t\t\tsorted_target = target[sorted_indices]\n",
    "\n",
    "\t\t\t# sprawdź podziały jeśli pomiędzy x_i a x_i+1 jest różnica w klasie decyzyjnej i wartości\n",
    "\t\t\tsplits = np.intersect1d(np.where(sorted_target[:-1] != sorted_target[1:])[0], np.where(sorted_attr[:-1] != sorted_attr[1:])[0])\n",
    "\t\t\tfor split_index in splits:\n",
    "\t\t\t\tsplit_gain = measure_split_value(sorted_target, split_index)\n",
    "\t\t\t\tif split_gain > best_split_gain:\n",
    "\t\t\t\t\tbest_split_gain = split_gain\n",
    "\t\t\t\t\tself.best_split = (i, sorted_attr[split_index]) # (atrybut, wartość podziału <= na lewo)\n",
    "\n",
    "\t\tif self.best_split is not None:\n",
    "\t\t\tdata_l, target_l, data_r, target_r = split_data(data, target, self.best_split)\n",
    "\t\t\tif (len(data_l) == 0 or len(data_r) == 0):\n",
    "\t\t\t\tprint()\n",
    "\t\t\t\traise Exception\n",
    "\t\t\tself.left = TreeNode()\n",
    "\t\t\tself.right = TreeNode()\n",
    "\t\t\tself.left.fit(data_l, target_l)\n",
    "\t\t\tself.right.fit(data_r, target_r)\n",
    "\t\telse:\n",
    "\t\t\tself.value = target[0]\n",
    "\t\t\n",
    "\n",
    "\t\n",
    "\tdef predict(self, data):\n",
    "\t\t\"\"\"\n",
    "\t\tArgumenty:\n",
    "\t\tdata -- numpy.ndarray, macierz cech o wymiarach (n, m), gdzie n to liczba przykładów, a m to liczba cech\n",
    "\n",
    "\t\tWartość zwracana:\n",
    "\t\tnumpy.ndarray, wektor przewidzoanych klas o długości n, gdzie n to liczba przykładów\n",
    "\t\t\"\"\"\n",
    "\t\ty_pred = np.zeros(data.shape[0])\n",
    "\t\tfor i, x in enumerate(data):\n",
    "\t\t\tnode = self\n",
    "\t\t\twhile node and node.value is None:\n",
    "\t\t\t\tif x[node.best_split[0]] > node.best_split[1]:\n",
    "\t\t\t\t\tnode = node.right\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnode = node.left\n",
    "\t\t\tif node.value:\n",
    "\t\t\t\ty_pred[i] = node.value\n",
    "\t\treturn y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład trenowanie i testowania drzewa\n",
    " \n",
    "Później znajduje się przykład trenowania i testowania drzewa na zbiorze danych `iris`, który zawierający 150 próbek irysów, z czego każda próbka zawiera 4 atrybuty: długość i szerokość płatków oraz długość i szerokość działki kielicha. Każda próbka należy do jednej z trzech klas: `setosa`, `versicolor` lub `virginica`, które są zakodowane jak int.\n",
    "\n",
    "Możesz go wykorzystać do testowania swojej implementacji. Możesz też zaimplementować własne testy lub użyć innych zbiorów danych, np. innych [zbiorów danych z scikit-learn](https://scikit-learn.org/stable/datasets/toy_dataset.html#toy-datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=2042)\n",
    "\n",
    "tree_model = TreeNode()\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred = tree_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
