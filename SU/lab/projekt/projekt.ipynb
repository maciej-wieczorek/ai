{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.describe().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.hist(bins=100, figsize=(16, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['company size', 'location', 'technology', 'seniority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = ['rozmiar firmy', 'lokalizacja', 'technologia', 'doświadczenie']\n",
    "titles = ['rozmiariu firmy', 'lokalizacji', 'technologii', 'doświadczenia']\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(2, 2, figsize=(14, 12))\n",
    "ax = ax.flatten()\n",
    "for i, feature_name in enumerate(categorical_features):\n",
    "\n",
    "    # for tick in ax[i].get_xticklabels():\n",
    "    #     tick.set_rotation(10)\n",
    "    bars1 = ax[i].barh([str(x) for x in jobs_df[feature_name].value_counts().sort_values().index], jobs_df[feature_name].value_counts().sort_values().values)\n",
    "    ax[i].set_title(f'Liczba ofert w zależności od {titles[i]}')\n",
    "    ax[i].set_ylabel(x_labels[i])\n",
    "    ax[i].set_xlabel('Liczba ofert')\n",
    "    ax[i].bar_label(bars1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df['company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_both_salary_df = jobs_df[~jobs_df[['salary b2b min', 'salary b2b max', 'salary employment min', 'salary employment max']].isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_b2b_rate_df = (((jobs_both_salary_df['salary b2b min'] + jobs_both_salary_df['salary b2b max']) / 2) / ((jobs_both_salary_df['salary employment min'] + jobs_both_salary_df['salary employment max']) / 2))\n",
    "employment_b2b_rate_mean = employment_b2b_rate_df.mean()\n",
    "employment_b2b_rate_std = employment_b2b_rate_df.std()\n",
    "print(employment_b2b_rate_mean, employment_b2b_rate_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df['salary'] = 0\n",
    "for i, row in jobs_df.iterrows():\n",
    "    if row.isna()['salary b2b min']:\n",
    "        jobs_df.loc[i, 'salary']  = ((row['salary employment min'] + row['salary employment max']) / 2) * employment_b2b_rate_mean\n",
    "    else:\n",
    "        jobs_df.loc[i, 'salary']  = (row['salary b2b min'] + row['salary b2b max']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df[['company size', 'year', 'month', 'salary']].corr()['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = ['rozmiar firmy', 'lokalizacja', 'technologia', 'doświadczenie']\n",
    "titles = ['rozmiariu firmy', 'lokalizacji', 'technologii', 'doświadczenia']\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(2, 2, figsize=(14, 12))\n",
    "ax = ax.flatten()\n",
    "for i, feature_name in enumerate(categorical_features):\n",
    "    bars1 = ax[i].barh([str(x) for x in jobs_df.groupby(feature_name)['salary'].mean().sort_values().index], jobs_df.groupby(feature_name)['salary'].mean().sort_values().values, xerr=jobs_df.groupby(feature_name)['salary'].std().sort_values().values)\n",
    "    ax[i].set_title(f'Średnie zarobki w zależności od {titles[i]}')\n",
    "    ax[i].set_ylabel(x_labels[i])\n",
    "    ax[i].set_xlabel('Średnie zarobki')\n",
    "    ax[i].bar_label(bars1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(2, 2, figsize=(14, 12))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, feature_name in enumerate(categorical_features):\n",
    "    # Prepare data for box plot\n",
    "    labels = jobs_df.groupby(feature_name)['salary'].mean().sort_values().index\n",
    "    data_to_plot = [jobs_df[jobs_df[feature_name] == category]['salary'] for category in labels]\n",
    "    \n",
    "    # Create box plot\n",
    "    ax[i].boxplot(data_to_plot, vert=False, patch_artist=True, labels=labels)\n",
    "    ax[i].set_title(f'Rozkład zarobków w zależności od {titles[i]}')\n",
    "    ax[i].set_ylabel(x_labels[i])\n",
    "    ax[i].set_xlabel('Zarobki')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(2, 2, figsize=(14, 12))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, feature_name in enumerate(categorical_features):\n",
    "    # Prepare data for box plot\n",
    "    labels = jobs_df.groupby(feature_name)['salary'].mean().sort_values().index\n",
    "    data_to_plot = [jobs_df[jobs_df[feature_name] == category]['salary'] for category in labels]\n",
    "    \n",
    "    # Create box plot\n",
    "    r = ax[i].violinplot(data_to_plot, vert=False, showmedians=True, showmeans=True)\n",
    "    r['cmeans'].set_color('g')\n",
    "    r['cmedians'].set_color('r')\n",
    "    ax[i].set_title(f'Rozkład zarobków w zależności od {titles[i]}')\n",
    "    ax[i].set_yticks(range(1, len(labels) + 1))\n",
    "    ax[i].set_yticklabels(labels)\n",
    "    ax[i].set_ylabel(x_labels[i])\n",
    "    ax[i].set_xlabel('Zarobki')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpy = jobs_df.copy()\n",
    "company_size_order = [1, 10, 100, 1000, 10000, 100000]\n",
    "df_cpy['company size'] = pd.Categorical(df_cpy['company size'], categories=company_size_order, ordered=True)\n",
    "salary_matrix = df_cpy.groupby(['technology', 'company size'])[target].mean().unstack()\n",
    "salary_matrix.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpy = jobs_df.copy()\n",
    "company_size_order = [1, 10, 100, 1000, 10000, 100000]\n",
    "df_cpy['company size'] = pd.Categorical(df_cpy['company size'], categories=company_size_order, ordered=True)\n",
    "salary_matrix = df_cpy.groupby(['technology', 'company size'])[target].count().unstack()\n",
    "salary_matrix.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpy = jobs_df.copy()\n",
    "company_size_order = [1, 10, 100, 1000, 10000, 100000]\n",
    "df_cpy['company size'] = pd.Categorical(df_cpy['company size'], categories=company_size_order, ordered=True)\n",
    "salary_matrix = df_cpy.groupby(['technology', 'company size'])[target].count().unstack()\n",
    "salary_matrix = salary_matrix.apply(lambda x: x / x.sum(), axis=1)\n",
    "salary_matrix.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpy = jobs_df.copy()\n",
    "company_size_order = [1, 10, 100, 1000, 10000, 100000]\n",
    "df_cpy['company size'] = pd.Categorical(df_cpy['company size'], categories=company_size_order, ordered=True)\n",
    "salary_matrix = df_cpy.groupby(['technology', 'company size'])[target].count().unstack()\n",
    "salary_matrix = salary_matrix.apply(lambda x: x / x.sum(), axis=0)\n",
    "salary_matrix.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpy = jobs_df.copy()\n",
    "seniority_order = ['junior', 'mid', 'senior', 'expert']\n",
    "df_cpy['seniority'] = pd.Categorical(df_cpy['seniority'], categories=seniority_order, ordered=True)\n",
    "salary_matrix = df_cpy.groupby(['technology', 'seniority'])[target].count().unstack()\n",
    "salary_matrix.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpy = jobs_df.copy()\n",
    "seniority_order = ['junior', 'mid', 'senior', 'expert']\n",
    "df_cpy['seniority'] = pd.Categorical(df_cpy['seniority'], categories=seniority_order, ordered=True)\n",
    "salary_matrix = df_cpy.groupby(['technology', 'seniority'])[target].std().unstack()\n",
    "salary_matrix.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpy = jobs_df.copy()\n",
    "seniority_order = ['junior', 'mid', 'senior', 'expert']\n",
    "df_cpy['seniority'] = pd.Categorical(df_cpy['seniority'], categories=seniority_order, ordered=True)\n",
    "salary_matrix = df_cpy.groupby(['technology', 'seniority'])[target].mean().unstack()\n",
    "salary_matrix.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.dropna(subset=['location', 'technology', 'seniority']).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_filtered_df = jobs_df.dropna(subset=['location', 'technology', 'seniority', target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = jobs_filtered_df.filter(regex='^(?!.*salary).*').drop('company', axis=1)\n",
    "X['company size'] = X['company size'].astype(str)\n",
    "y = jobs_filtered_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noop_transformer = FunctionTransformer(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "num_pipeline = make_pipeline(noop_transformer)\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (cat_pipeline, make_column_selector(dtype_include=object)),\n",
    "    (num_pipeline, make_column_selector(dtype_include=np.number))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "values = []\n",
    "errs = []\n",
    "for regressor in [LinearRegression(), KNeighborsRegressor(), RandomForestRegressor(), SVR(), Lasso(), Ridge(), MLPRegressor()]:\n",
    "    name = str(regressor)[:-2]\n",
    "\n",
    "    scores = cross_val_score(make_pipeline(preprocessing, regressor), X_train, y_train, n_jobs=-1, cv=10, scoring=make_scorer(mean_absolute_error))\n",
    "    mean = scores.mean()\n",
    "    std = scores.std()\n",
    "    \n",
    "    labels.append(name)\n",
    "    values.append(mean)\n",
    "    errs.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "bar1 = ax.barh(labels, values, xerr=errs, height=0.5)\n",
    "ax.set_label('Mean absolute Error')\n",
    "ax.set_xlabel('Wartości metryki')\n",
    "ax.set_ylabel('Model')\n",
    "ax.set_title('Porównanie modeli')\n",
    "ax.legend(['Mean absolute Error'], loc='lower left')\n",
    "ax.bar_label(bar1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessing, RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'randomforestregressor__n_estimators': [100, 200, 300],\n",
    "    'randomforestregressor__max_depth': [None, 1, 3, 10],\n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestregressor__max_features': [1, 'sqrt', 'log2']\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist, n_iter=10, cv=10, n_jobs=-1, scoring='neg_mean_absolute_error', verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_rf = random_search.best_estimator_\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = make_pipeline(preprocessing, RandomForestRegressor(n_estimators=300, max_depth=None, min_samples_split=2, min_samples_leaf=2, max_features='log2'))\n",
    "best_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, best_rf.predict(X_test), color='blue')\n",
    "plt.plot(y_test, y_test, color='red', linestyle='--')\n",
    "plt.title('Poprawne wartości a przewidziane wartości')\n",
    "plt.xlabel('Poprawne wartości')\n",
    "plt.ylabel('Przewidziane wartości')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_rf = list(best_rf.named_steps.items())[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_rf.named_steps.values())[0].transform(X[:1]).todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_rf.named_steps.values())[0].transform(X[:1]).todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_rf_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Znaczenie cech\")\n",
    "plt.barh(indices, importances, align=\"center\")\n",
    "plt.xlabel(\"Znaczenie\")\n",
    "plt.ylabel(\"Cecha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lin = make_pipeline(preprocessing, LinearRegression())\n",
    "best_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_lin.named_steps.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(best_lin.named_steps.values())[1].coef_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Znaczenie cech\")\n",
    "plt.barh(indices, importances, align=\"center\")\n",
    "plt.xlabel(\"Znaczenie\")\n",
    "plt.ylabel(\"Cecha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Export the structure of a single tree from the forest\n",
    "estimator = best_rf_rf.estimators_[-1]\n",
    "\n",
    "# Method 1: Using graphviz\n",
    "dot_data = export_graphviz(estimator, out_file=None, \n",
    "                           feature_names=[f'Feature {i}' for i in range(len(best_rf_rf.feature_importances_))],\n",
    "                           filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"tree\", format='png')\n",
    "\n",
    "# # Method 2: Using plot_tree\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plot_tree(estimator, feature_names=[f'Feature {i}' for i in range(len(best_rf_rf.feature_importances_))], filled=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_rf.named_steps.values())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(best_rf.named_steps.values())[0].transform(X).todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(list(best_rf.named_steps.values())[1], list(best_rf.named_steps.values())[0].transform(X[:100]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(list(best_rf.named_steps.values())[0].transform(X[:500]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
