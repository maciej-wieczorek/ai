{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import imblearn.pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('148141-ensembles.txt', sep='\\t')\n",
    "# data = data.sample(frac=0.05)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "X=data.iloc[:,0:-1].to_numpy()\n",
    "y=data.iloc[:,-1].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_cv(classifier, X, y):\n",
    "    a = []\n",
    "    # for scoring in [accuracy_score, geometric_mean_score, roc_auc_score]:\n",
    "    for scoring in [geometric_mean_score]:\n",
    "        scores = cross_val_score(classifier, X, y, cv=10, scoring=make_scorer(scoring))\n",
    "        a.append((scores.mean(), scores.std()))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_conf_matrix(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    plt.tight_layout()\n",
    "    cm = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred))\n",
    "    cm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((len(data[data['class'] == 1]) / len(data)) * (len(data[data['class'] == 0]) / len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "data.hist(figsize=(50, 30), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,:-1].boxplot(figsize=(70, 10))\n",
    "plt.xticks(rotation=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(data)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "plt.scatter(X2D[:, 0], X2D[:, 1], c=data['class'], alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.title('PCA 2D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "pca = PCA(n_components=3)\n",
    "X2D = pca.fit_transform(data)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X2D[:, 0], X2D[:, 1], X2D[:, 2], c=data['class'], alpha=0.5)\n",
    "plt.title('PCA 3D')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=len(data.columns)-1)\n",
    "_ = pca.fit_transform(data)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Liczba wymiar√≥w')\n",
    "plt.xticks(np.arange(0, len(pca.explained_variance_ratio_), 10.0))\n",
    "plt.ylabel('Zachowana wariancja')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "\n",
    "}\n",
    "\n",
    "metrics['RandomForestClassifier'] = get_metrics_cv(RandomForestClassifier().fit(X, y), X, y)\n",
    "print(metrics)\n",
    "metrics['AdaBoostClassifier'] = get_metrics_cv(AdaBoostClassifier(base_estimator=LogisticRegression()).fit(X, y), X, y)\n",
    "print(metrics)\n",
    "metrics['VotingClassifier'] = get_metrics_cv(VotingClassifier(estimators=[('lr', LogisticRegression()), ('dt', DecisionTreeClassifier()), ('knn', KNeighborsClassifier())]).fit(X, y), X, y)\n",
    "print(metrics)\n",
    "metrics['StackingClassifier'] = get_metrics_cv(StackingClassifier(estimators=[('lr', LogisticRegression()), ('dt', DecisionTreeClassifier()), ('knn', KNeighborsClassifier())], final_estimator=LogisticRegression()).fit(X, y), X, y)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, values in metrics.items():\n",
    "    print(f'{clf}: {[(round(x[0], 4),round(x[1],4)) for x in values]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_norm = {\n",
    "\n",
    "}\n",
    "\n",
    "metrics_norm['RandomForestClassifier'] = get_metrics_cv(make_pipeline(StandardScaler(), RandomForestClassifier().fit(X, y)), X, y)\n",
    "print(metrics_norm)\n",
    "metrics_norm['AdaBoostClassifier'] = get_metrics_cv(make_pipeline(StandardScaler(), AdaBoostClassifier(base_estimator=LogisticRegression())).fit(X, y), X, y)\n",
    "print(metrics_norm)\n",
    "metrics_norm['VotingClassifier'] = get_metrics_cv(make_pipeline(StandardScaler(), VotingClassifier(estimators=[('lr', LogisticRegression()), ('dt', DecisionTreeClassifier()), ('knn', KNeighborsClassifier())])).fit(X, y), X, y)\n",
    "print(metrics_norm)\n",
    "metrics_norm['StackingClassifier'] = get_metrics_cv(make_pipeline(StandardScaler(), StackingClassifier(estimators=[('lr', LogisticRegression()), ('dt', DecisionTreeClassifier()), ('knn', KNeighborsClassifier())], final_estimator=LogisticRegression())).fit(X, y), X, y)\n",
    "print(metrics_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, values in metrics_norm.items():\n",
    "    print(f'{clf}: {[(round(x[0], 4),round(x[1],4)) for x in values]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=make_pipeline(StandardScaler(), AdaBoostClassifier()), param_grid=param_grid, scoring=make_scorer(geometric_mean_score),cv=5, n_jobs=4, verbose=2)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform GridSearchCV with AdaBoost and a given base estimator\n",
    "def perform_grid_search(base_estimator, param_grid):\n",
    "    adaboost = AdaBoostClassifier(base_estimator=base_estimator)\n",
    "    grid_search = GridSearchCV(estimator=make_pipeline(StandardScaler(), adaboost), param_grid=param_grid, scoring=make_scorer(geometric_mean_score),cv=5, n_jobs=4, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Define parameter grids for different base estimators\n",
    "param_grid_dt = {\n",
    "    'adaboostclassifier__base_estimator__max_depth': [1, 2, 3],\n",
    "    'adaboostclassifier__n_estimators': [50, 100, 150],\n",
    "    'adaboostclassifier__learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'adaboostclassifier__base_estimator__C': [0.01, 0.1, 1, 10],\n",
    "    'adaboostclassifier__n_estimators': [50, 100, 150],\n",
    "    'adaboostclassifier__learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'adaboostclassifier__base_estimator__C': [0.1, 1, 10],\n",
    "    'adaboostclassifier__base_estimator__kernel': ['linear', 'rbf'],\n",
    "    'adaboostclassifier__n_estimators': [50, 100],\n",
    "    'adaboostclassifier__learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid_search_dt = perform_grid_search(DecisionTreeClassifier(), param_grid_dt)\n",
    "print(\"DecisionTree Best Parameters:\", grid_search_dt.best_params_)\n",
    "print(\"DecisionTree Best Cross-Validation Score:\", grid_search_dt.best_score_)\n",
    "\n",
    "grid_search_lr = perform_grid_search(LogisticRegression(max_iter=1000), param_grid_lr)\n",
    "print(\"LogisticRegression Best Parameters:\", grid_search_lr.best_params_)\n",
    "print(\"LogisticRegression Best Cross-Validation Score:\", grid_search_lr.best_score_)\n",
    "\n",
    "grid_search_svm = perform_grid_search(SVC(probability=True), param_grid_svm)\n",
    "print(\"SVM Best Parameters:\", grid_search_svm.best_params_)\n",
    "print(\"SVM Best Cross-Validation Score:\", grid_search_svm.best_score_)\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "best_models = {\n",
    "    \"DecisionTree\": grid_search_dt.best_estimator_,\n",
    "    \"LogisticRegression\": grid_search_lr.best_estimator_,\n",
    "    \"SVM\": grid_search_svm.best_estimator_\n",
    "}\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = geometric_mean_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Test Set G-mean: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree Best Parameters: {'adaboostclassifier__base_estimator__max_depth': 1, 'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 100}\n",
    "# DecisionTree Best Cross-Validation Score: 0.7963328787509274\n",
    "\n",
    "adaBoost = imblearn.pipeline.make_pipeline(StandardScaler(), AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1, n_estimators=100))\n",
    "tree = imblearn.pipeline.make_pipeline(StandardScaler(), DecisionTreeClassifier(max_depth=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_metrics_cv(adaBoost, X, y))\n",
    "print(get_metrics_cv(tree, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoost.fit(X_train, y_train)\n",
    "print(make_scorer(geometric_mean_score)(adaBoost, X_test, y_test))\n",
    "tree.fit(X_train, y_train)\n",
    "print(make_scorer(geometric_mean_score)(tree, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_conf_matrix(adaBoost, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_conf_matrix(tree, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
