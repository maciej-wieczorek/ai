{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, accuracy_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('148141-imbalanced.txt', sep='\\t')\n",
    "# data = data.sample(frac=0.05)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "X=data.iloc[:,0:-1].to_numpy()\n",
    "y=data.iloc[:,-1].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_cv(classifier, X, y):\n",
    "    a = []\n",
    "    for scoring in [accuracy_score, geometric_mean_score, roc_auc_score]:\n",
    "        scores = cross_val_score(classifier, X, y, cv=10, scoring=make_scorer(scoring))\n",
    "        a.append((scores.mean(), scores.std()))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((len(data[data['class'] == 1]) / len(data)) * (len(data[data['class'] == 0]) / len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.hist(figsize=(50, 30), bins=100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.iloc[:,:-1].boxplot(figsize=(70, 10))\n",
    "plt.xticks(rotation=25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(data)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "plt.scatter(X2D[:, 0], X2D[:, 1], c=data['class'])\n",
    "plt.tight_layout()\n",
    "plt.title('PCA 2D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "pca = PCA(n_components=3)\n",
    "X2D = pca.fit_transform(data)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(X2D[:, 0], X2D[:, 1], X2D[:, 2], c=data['class'])\n",
    "plt.title('PCA 3D')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=len(data.columns)-1)\n",
    "_ = pca.fit_transform(data)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Liczba wymiarów')\n",
    "plt.xticks(np.arange(0, len(pca.explained_variance_ratio_), 10.0))\n",
    "plt.ylabel('Zachowana wariancja')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "\n",
    "}\n",
    "\n",
    "metrics['KNeighborsClassifier'] = get_metrics_cv(make_pipeline(SMOTE(), KNeighborsClassifier()).fit(X, y), X, y)\n",
    "metrics['DecisionTreeClassifier'] = get_metrics_cv(make_pipeline(SMOTE(), DecisionTreeClassifier()).fit(X, y), X, y)\n",
    "metrics['RandomForestClassifier'] = get_metrics_cv(make_pipeline(SMOTE(), RandomForestClassifier()).fit(X, y), X, y)\n",
    "metrics['SVC'] = get_metrics_cv(make_pipeline(SMOTE(), SVC()).fit(X, y), X, y)\n",
    "metrics['MLPClassifier'] = get_metrics_cv(make_pipeline(SMOTE(), MLPClassifier()).fit(X, y), X, y)\n",
    "metrics['GaussianNB'] = get_metrics_cv(make_pipeline(SMOTE(), GaussianNB()).fit(X, y), X, y)\n",
    "metrics['QuadraticDiscriminantAnalysis'] = get_metrics_cv(make_pipeline(SMOTE(), QuadraticDiscriminantAnalysis()).fit(X, y), X, y)\n",
    "metrics['ZeroR'] = get_metrics_cv(make_pipeline(DummyClassifier()).fit(X, y), X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, values in metrics.items():\n",
    "    print(f'{clf}: {[(round(x[0], 4),round(x[1],4)) for x in values]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(metrics.keys())\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.15\n",
    "index = range(len(models))\n",
    "\n",
    "bar1 = ax.bar(index, [val[0][0] for val in metrics.values()], bar_width, yerr=[val[0][1] for val in metrics.values()], label='Accuracy')\n",
    "bar2 = ax.bar([i + bar_width for i in index], [val[1][0] for val in metrics.values()], bar_width, yerr=[val[1][1] for val in metrics.values()], label='G-mean')\n",
    "bar3 = ax.bar([i + 2*bar_width for i in index], [val[2][0] for val in metrics.values()], bar_width, yerr=[val[2][1] for val in metrics.values()], label='ROC AUC')\n",
    "\n",
    "ax.set_xlabel('Modele')\n",
    "ax.set_ylabel('Wartości metryk')\n",
    "ax.set_title('Porównanie modeli do klasyfikacji niezbalansowanych danych')\n",
    "ax.set_xticks([i + bar_width/2 for i in index])\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_norm = {\n",
    "\n",
    "}\n",
    "\n",
    "metrics_norm['KNeighborsClassifier'] = get_metrics_cv(make_pipeline(StandardScaler(),SMOTE(),  KNeighborsClassifier()).fit(X, y), X, y)\n",
    "metrics_norm['DecisionTreeClassifier'] = get_metrics_cv(make_pipeline(StandardScaler(), SMOTE(), DecisionTreeClassifier()).fit(X, y), X, y)\n",
    "metrics_norm['RandomForestClassifier'] = get_metrics_cv(make_pipeline(StandardScaler(), SMOTE(), RandomForestClassifier()).fit(X, y), X, y)\n",
    "metrics_norm['SVC'] = get_metrics_cv(make_pipeline(StandardScaler(), SMOTE(), SVC()).fit(X, y), X, y)\n",
    "metrics_norm['MLPClassifier'] = get_metrics_cv(make_pipeline( StandardScaler(), SMOTE(),MLPClassifier()).fit(X, y), X, y)\n",
    "metrics_norm['GaussianNB'] = get_metrics_cv(make_pipeline(StandardScaler(),SMOTE(),  GaussianNB()).fit(X, y), X, y)\n",
    "metrics_norm['QuadraticDiscriminantAnalysis'] = get_metrics_cv(make_pipeline(StandardScaler(), SMOTE(), QuadraticDiscriminantAnalysis()).fit(X, y), X, y)\n",
    "metrics_norm['ZeroR'] = get_metrics_cv(make_pipeline(StandardScaler(), DummyClassifier()).fit(X, y), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, values in metrics_norm.items():\n",
    "    print(f'{clf}: {[(round(x[0], 4),round(x[1],4)) for x in values]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(metrics_norm.keys())\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.15\n",
    "index = range(len(models))\n",
    "\n",
    "bar1 = ax.bar(index, [val[0][0] for val in metrics_norm.values()], bar_width, yerr=[val[0][1] for val in metrics_norm.values()], label='Accuracy')\n",
    "bar2 = ax.bar([i + bar_width for i in index], [val[1][0] for val in metrics_norm.values()], bar_width, yerr=[val[1][1] for val in metrics_norm.values()], label='G-mean')\n",
    "bar3 = ax.bar([i + 2*bar_width for i in index], [val[2][0] for val in metrics_norm.values()], bar_width, yerr=[val[2][1] for val in metrics_norm.values()], label='ROC AUC')\n",
    "\n",
    "ax.set_xlabel('Modele')\n",
    "ax.set_ylabel('Wartości metryk')\n",
    "ax.set_title('Porównanie modeli do klasyfikacji niezbalansowanych danych po standaryzacji')\n",
    "ax.set_xticks([i + bar_width/2 for i in index])\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(metrics_norm.keys())\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.15\n",
    "index = range(len(models))\n",
    "\n",
    "bar_1_vals = []\n",
    "bar_2_vals = []\n",
    "bar_3_vals = []\n",
    "for key in metrics_norm:\n",
    "    bar_1_vals.append(metrics_norm[key][0][0] - metrics[key][0][0])\n",
    "    bar_2_vals.append(metrics_norm[key][1][0] - metrics[key][1][0])\n",
    "    bar_3_vals.append(metrics_norm[key][2][0] - metrics[key][2][0])\n",
    "\n",
    "\n",
    "bar1 = ax.bar(index, bar_1_vals, bar_width, label='Accuracy')\n",
    "bar2 = ax.bar([i + bar_width for i in index], bar_2_vals, bar_width, label='G-mean')\n",
    "bar3 = ax.bar([i + 2*bar_width for i in index], bar_3_vals, bar_width, label='ROC AUC')\n",
    "\n",
    "ax.set_xlabel('Modele')\n",
    "ax.set_ylabel('Wartości metryk')\n",
    "ax.set_title('Porównanie modeli po standaryzacji do modeli bez standaryzacji')\n",
    "ax.set_xticks([i + bar_width/2 for i in index])\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=make_pipeline(SMOTE(), SVC()), param_grid=param_grid, scoring=make_scorer(geometric_mean_score),cv=5, n_jobs=4, verbose=2)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "results = grid_search.cv_results_\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results[df_results['param_svc__kernel'] == 'poly']\n",
    "heatmap_data = df_results.pivot(index='param_svc__C', columns='param_svc__gamma', values='mean_test_score')\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\", fmt=\".4g\")\n",
    "plt.title('Wartości G-mean w Grid Search CV dla SVC-poly')\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "model_exp = make_pipeline(SMOTE(), SVC(kernel='rbf', C=0.1, gamma=0.1, probability=True))\n",
    "model_exp.fit(X_train, y_train)\n",
    "print(get_metrics_cv(model_exp, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model_exp.predict, X_test, feature_names=data.columns[:-1])\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, max_display=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "class_weights = [\n",
    "    {0: 0.5, 1: 0.5},\n",
    "    {0: 0.95, 1: 0.05},\n",
    "    'balanced',\n",
    "    {0: 0.99, 1: 0.01},\n",
    "    {0: 0.995, 1: 0.005},\n",
    "    {0: 0.999, 1: 0.001},\n",
    "]\n",
    "\n",
    "# Lista do przechowywania wyników\n",
    "results = []\n",
    "weights_labels = []\n",
    "\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "fig.set_size_inches(8, 10)\n",
    "\n",
    "for i, weight in enumerate(class_weights):\n",
    "    # Trening modelu\n",
    "    clf = DecisionTreeClassifier(class_weight=weight, max_depth=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predykcja\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    results.append((weight, cm))\n",
    "\n",
    "    weights_labels.append(str(weight))\n",
    "    # Wyświetlanie macierzy pomyłek\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=axs.reshape(-1)[i])\n",
    "    axs.reshape(-1)[i].set_title(f'Wagi: {weight}')\n",
    "\n",
    "print(get_metrics_cv(clf, X, y))\n",
    "fig.show()\n",
    "# Analiza wyników\n",
    "false_positives = [cm[0, 1] for _, cm in results]\n",
    "false_negatives = [cm[1, 0] for _, cm in results]\n",
    "\n",
    "# Wykres FP i FN\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(weights_labels, false_positives, marker='o', label='FP')\n",
    "plt.plot(weights_labels, false_negatives, marker='o', label='FN')\n",
    "plt.xlabel('Wagi')\n",
    "plt.ylabel('Ilość pomyłek')\n",
    "plt.title('Rodzaje pomyłek w zależności od wag')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
