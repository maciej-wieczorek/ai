{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnfR93M1k7px"
      },
      "source": [
        "# The α algorithm\n",
        "\n",
        "A [Petri net](https://en.wikipedia.org/wiki/Petri_net) is a graph-based process model with nodes of two types: places and transitions. Places are containers for tokens that may contain zero, one, or more tokens. Transitions are activities. A transition is enabled if all its directly preceding (input) places have at least one token. The transition fires by consuming exactly one token from each input place and producing exactly one token to each output place.\n",
        "\n",
        "Worfklow net (WF-net) is a Petri net with the designated start and end places and made of a single [connected component](https://en.wikipedia.org/wiki/Component_(graph_theory)). WF-nets are devoted to model business processes. For WF-net, a business case begins when a token is put into the start place. For sound (see Lecture 2) WF-net the process ends when the token appears in the end place. For unsound WF-nets, it may happen that the appearance of the token in the end place does not end the process.\n",
        "\n",
        "The α algorithm is a very simple algorithm for discovering WF-nets from event logs. See Lecture 6 for the details on the α algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73kFX4sJqvCh"
      },
      "source": [
        "## Preliminaries\n",
        "\n",
        "Install PM4Py package and download event logs for exercises."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_VPxSsVkSAX"
      },
      "outputs": [],
      "source": [
        "# !pip install pm4py\n",
        "# !pip install pyvis\n",
        "# !wget http://www.cs.put.poznan.pl/tpawlak/files/EP/RoadTrafficFineManagement.xes.gz\n",
        "\n",
        "# from google.colab import data_table\n",
        "# data_table.enable_dataframe_formatter()\n",
        "\n",
        "# from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, IFrame, Markdown\n",
        "from pm4py.algo.filtering.log.start_activities import start_activities_filter\n",
        "from pm4py.algo.filtering.log.end_activities import end_activities_filter\n",
        "from pm4py.statistics.end_activities.log import get as end_activities_get\n",
        "from pm4py.algo.filtering.log.start_activities import start_activities_filter\n",
        "\n",
        "import base64\n",
        "\n",
        "import pandas as pd\n",
        "import pm4py\n",
        "\n",
        "def view_html(filename: str):\n",
        "  display(IFrame(src=\"data:text/html;base64,\" + base64.b64encode(open(filename, \"rb\").read()).decode(\"ascii\"), width=1000, height=1000))\n",
        "\n",
        "def printmd(string):\n",
        "  display(Markdown(string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJpFI9EcrIFx"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "Import the `RoadTrafficFineManagement.xes.gz` event log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrYymA8HsbkC"
      },
      "outputs": [],
      "source": [
        "log = pm4py.read_xes(\"Sepsis.xes.gz\", variant=\"iterparse20\")\n",
        "\n",
        "# integer_features = [\"article\", \"points\"]\n",
        "# for feature in integer_features:\n",
        "#   log[feature] = log[feature].astype(\"Int32\")\n",
        "\n",
        "# nominal_features = [\"org:resource\", \"article\", \"dismissal\", \"vehicleClass\", \"notificationType\", \"lastSent\"]\n",
        "# for feature in nominal_features:\n",
        "#   log[feature] = log[feature].astype(\"string\")\n",
        "\n",
        "log[:10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-MXXqUyuLdD"
      },
      "source": [
        "Analyze the event log and answer the questions:\n",
        "* How many traces and events are in the event log?\n",
        "561470, 150370\n",
        "* What are the activities in the event log?\n",
        "'Create Fine', 'Send Fine', 'Insert Fine Notification',\n",
        "       'Add penalty', 'Send for Credit Collection', 'Payment',\n",
        "       'Insert Date Appeal to Prefecture', 'Send Appeal to Prefecture',\n",
        "       'Receive Result Appeal from Prefecture',\n",
        "       'Notify Result Appeal to Offender', 'Appeal to Judge'\n",
        "* What is the time window for the event log?\n",
        "Timestamp('2000-01-01 00:00:00+0000', tz='UTC')-Timestamp('2013-06-18 00:00:00+0000', tz='UTC')\n",
        "* Which activities start and end the process?\n",
        "start: Create Fine, end: Send Fine, Payment\n",
        "* What resources are involved in individual activities?\n",
        "561\tCreate Fine\n",
        "* What is the distribution of fine amount?\n",
        "prawoskośny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnCRpYPSukDA"
      },
      "outputs": [],
      "source": [
        "# n_traces = # TODO: calculate number of traces\n",
        "# print(f\"# traces: {n_traces}\")\n",
        "\n",
        "# n_events = # TODO: calculate number of events\n",
        "# print(f\"# events: {n_events} ({float(n_events)/n_traces} per trace)\")\n",
        "\n",
        "# timestamp_attribute = \"\" # TODO: set the name of the attribute holding time information\n",
        "# beginning = log[timestamp_attribute].min()\n",
        "# end = log[timestamp_attribute].max()\n",
        "# print(f\"Time window: {beginning} - {end} ({end - beginning})\")\n",
        "\n",
        "activity_attribute = \"concept:name\" # TODO: set the name of the attribute holding the activity name\n",
        "activities = log.groupby(activity_attribute)[activity_attribute].count()\n",
        "printmd(\"**Acitivites:**\")\n",
        "display(activities)\n",
        "\n",
        "# start_activities = pm4py... # TODO: find start activities\n",
        "# end_activities = pm4py... # TODO: find end activities\n",
        "# printmd(\"**Start activities:**\")\n",
        "# print(\", \".join(start_activities.keys()))\n",
        "# printmd(\"**End activities:**\")\n",
        "# print(\", \".join(end_activities.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_df = log.sort_values(by=[\"case:concept:name\", \"time:timestamp\"])\n",
        "\n",
        "# Get first event per case\n",
        "first_events = log_df.groupby(\"case:concept:name\").first().reset_index()\n",
        "\n",
        "# Get last event per case\n",
        "last_events = log_df.groupby(\"case:concept:name\").last().reset_index()\n",
        "\n",
        "# Filter cases where first activity is \"ER Registration\"\n",
        "cases_start = first_events[first_events[\"concept:name\"] == \"ER Registration\"][\"case:concept:name\"]\n",
        "\n",
        "# Filter cases where last activity is e.g. \"Discharge\" (replace with your desired end activity)\n",
        "cases_end = last_events[last_events[\"concept:name\"].isin([\"Release A\", \"Release B\", \"Release C\", \"Release D\", \"Release E\", \"Return ER\"])][\"case:concept:name\"]\n",
        "\n",
        "# Keep only cases where both conditions hold\n",
        "cases_to_keep = set(cases_start).intersection(set(cases_end))\n",
        "\n",
        "# Filter the original dataframe to only keep those cases\n",
        "filtered_log_df = log_df[log_df[\"case:concept:name\"].isin(cases_to_keep)].copy()\n",
        "len(filtered_log_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twsyIDzAu20U"
      },
      "source": [
        "How do look like the most common process variants?\n",
        "**Draw on a piece of paper the general structure of the process that reproduces at least 90% of the most common behavior.**\n",
        "\n",
        "Do people usually pay fines or not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variants = pm4py.get_variants(filtered_log_df)\n",
        "len(variants)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WacIGnDw0QvG"
      },
      "outputs": [],
      "source": [
        "common_variants = pd.DataFrame(variants.items(), columns=[\"variant\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "common_variants[\"percentile\"] = common_variants[\"count\"] * 100 / common_variants[\"count\"].sum()\n",
        "common_variants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "print(common_variants['variant'].head(30))\n",
        "pd.set_option('display.max_colwidth', 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k = 34\n",
        "common_variants[0:k]['percentile'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFP-vxbRwJP6"
      },
      "outputs": [],
      "source": [
        "display(common_variants[0:k])\n",
        "\n",
        "log_top_k = pm4py.filter_variants_top_k(filtered_log_df, k) # TODO: filter top k variants\n",
        "\n",
        "wfnet_inductive = pm4py.discover_petri_net_inductive(log_top_k) # TODO: discover WF-net using the Inductive Miner\n",
        "pm4py.vis.view_petri_net(*wfnet_inductive)\n",
        "\n",
        "from pm4py.algo.analysis.woflan import algorithm as woflan\n",
        "\n",
        "woflan_parameters = {\n",
        "    woflan.Parameters.RETURN_ASAP_WHEN_NOT_SOUND: False,\n",
        "    woflan.Parameters.PRINT_DIAGNOSTICS: True,\n",
        "    woflan.Parameters.RETURN_DIAGNOSTICS: False\n",
        "}\n",
        "\n",
        "is_sound = woflan.apply(*wfnet_inductive, parameters=woflan_parameters) # TODO: check soundness\n",
        "print(f\"Is sound: {is_sound}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceN2PIcL7m6l"
      },
      "source": [
        "Pick the model that you feel is the best and replay the log on it to add frequences of events/activities, and temporal information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yigFNzIouL-5"
      },
      "outputs": [],
      "source": [
        "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
        "\n",
        "net = wfnet_inductive # TODO: set WF-net that you feel the best\n",
        "\n",
        "# add frequencies\n",
        "parameters_freq = {pn_visualizer.Variants.FREQUENCY.value.Parameters.FORMAT: \"png\"}\n",
        "gviz_freq = pn_visualizer.apply(*net, parameters=parameters_freq, variant=pn_visualizer.Variants.FREQUENCY, log=log)\n",
        "pn_visualizer.view(gviz_freq)\n",
        "\n",
        "# add temporal information\n",
        "parameters_temp = {pn_visualizer.Variants.PERFORMANCE.value.Parameters.FORMAT: \"png\"}\n",
        "gviz_temp = pn_visualizer.apply(*net, parameters=parameters_temp, variant=pn_visualizer.Variants.PERFORMANCE, log=log)\n",
        "pn_visualizer.view(gviz_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3m5SWiO5kmD"
      },
      "source": [
        "Calculate fitness, precision, generalization, and simplicity for the best WF-net."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6hX2nY90HOq"
      },
      "outputs": [],
      "source": [
        "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
        "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
        "\n",
        "net = wfnet_inductive\n",
        "\n",
        "fitness = pm4py.fitness_alignments(log, *net) # TODO: calculate fitness using alignments\n",
        "precision = pm4py.precision_alignments(log, *net) # TODO: calculate precision using alignments\n",
        "generalization = generalization_evaluator.token_based.apply(log, *net) # TODO: calculate generalization using token-based replay\n",
        "simplicity = simplicity_evaluator.apply(net[0]) # TODO: calculate simplicity; what kind of measure is it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Fitness: {fitness}\")\n",
        "print(f\"Precision: {precision:.3f}\")  # 22 % przypadków nie ma w logu\n",
        "print(f\"Generalization: {generalization:.3f}\")\n",
        "print(f\"Simplicity: {simplicity:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HIorkWhMF2s"
      },
      "source": [
        "Replay each trace on this model using the alignment algorithm and visualize the result of conformance check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNUCihR05nGu"
      },
      "outputs": [],
      "source": [
        "alignments = pm4py... # TODO: calculate alignments of the log and model\n",
        "pm4py.vis.view_alignments(log, alignments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ojrEPOAMPHH"
      },
      "source": [
        "Explain decisions in the best WF-net using decision trees induced by replaying the event log on the WF-net.\n",
        "For performance reasons sample at most 2000 traces from the entire event log.\n",
        "\n",
        "Interpret the resulting decision trees in the context of the decision points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgSqXXrdzjox"
      },
      "outputs": [],
      "source": [
        "from pm4py.algo.decision_mining import algorithm as decision_mining\n",
        "from pm4py.visualization.petri_net import visualizer\n",
        "from pm4py.visualization.decisiontree import visualizer as tree_visualizer\n",
        "from sklearn import tree\n",
        "\n",
        "net =  # TODO: set the WF-net that you feel the best\n",
        "\n",
        "# View the WF-net\n",
        "pm4py.view_petri_net(*net)\n",
        "# View the identifiers of the nodes in the WF-net\n",
        "gviz = visualizer.apply(*net, parameters={visualizer.Variants.WO_DECORATION.value.Parameters.DEBUG: True})\n",
        "visualizer.view(gviz)\n",
        "\n",
        "# Sample the event log for performance reasons\n",
        "log_sample = pm4py... # TODO: sample 2000 traces from the event log\n",
        "\n",
        "decision_points = decision_mining... # TODO: get decision points\n",
        "for point in sorted(decision_points.keys()):\n",
        "  X, y, classes = decision_mining.apply(log_sample, *net, decision_point=point)\n",
        "  X = X.fillna(0)\n",
        "  X = X[~y.isna()]\n",
        "  y = y[~y.isna()]\n",
        "  classes = [str(c) for c in classes]\n",
        "\n",
        "  print(f\"Decision point: {point}; possible decisions: {classes}\")\n",
        "\n",
        "  dt = tree.DecisionTreeClassifier(max_depth=10, ccp_alpha=0.005)\n",
        "  dt = dt.fit(X, y)\n",
        "  feature_names = list(X.columns.values.tolist())\n",
        "\n",
        "  gviz = tree_visualizer.apply(dt, feature_names, classes)\n",
        "  tree_visualizer.view(gviz)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
